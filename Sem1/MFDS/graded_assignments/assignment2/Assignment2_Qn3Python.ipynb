{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Question: Gram-Schmidt Algorithm & QR Decomposition\n",
    "\n",
    "**i.** Write a code to generate a random matrix A of size $m × n$ with $m > n$ and calculate its Frobenius norm, $|| \\cdot ||_F$. The entries of A must be of the form r.dddd (example 5.4316). The inputs are the positive integers m and n and the output should display the the dimensions and the calculated norm value.\n",
    "\n",
    "\n",
    "\n",
    "> **Deliverable(s) : The code with the desired input and output (0.5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from typing import List, Tuple\n",
    "import random, math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A function to generate a random entry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_entry() -> float:\n",
    "    \"\"\"[Returns a random number of the form r.dddd]\n",
    "\n",
    "    Returns:\n",
    "        float: A random number\n",
    "    \"\"\"\n",
    "\n",
    "    digits = \"\"\n",
    "    for i in range(5):\n",
    "        dig = random.randint(0, 9)\n",
    "        if i == 4: dig = random.randint(1, 9)\n",
    "        digits = digits + str(dig)\n",
    "        if i == 0: digits += \".\"\n",
    "    return float(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "**Create a random matrix of m x n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_matrix(m:int, n:int, wide:bool = False) -> List:\n",
    "    \"\"\"[Takes in the number of rows and columns and generates a matrix of size m x n]\n",
    "\n",
    "    Args:\n",
    "        m (int): Number of rows of the matrix\n",
    "        n (int): Number of columns of the matrix\n",
    "        wide (bool, default = False): Whether wider or square matrix are allowed\n",
    "\n",
    "    Returns:\n",
    "        List: A matrix as a list of lists\n",
    "    \"\"\"\n",
    "    if not wide:\n",
    "        if m <= n:\n",
    "            print(\"Error: Requested matrix is square or wide; It must be tall. Please give m > n\")\n",
    "            return []\n",
    "    \n",
    "    A = []\n",
    "    for i in range(m):\n",
    "        ith_row = []\n",
    "        for j in range(n):\n",
    "            ith_row.append(generate_random_entry())\n",
    "        A.append(ith_row)\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "**Compute the frobenius norm of a matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frob_norm(A: List) -> Tuple:\n",
    "    \"\"\"[Takes in a matrix A and computes the frobenius norm of that matrix]\n",
    "\n",
    "    Args:\n",
    "        A (List): A matrix represented as List of Lists\n",
    "\n",
    "    Returns:\n",
    "        Tuple: [The frobenius norm of the matrix, and the number of additions, multiplications, divisions needed to compute the norm of the matrix]\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(A) == 0:\n",
    "        print(\"Empty matrix passed. Pass a finite matrix\")\n",
    "        return -1.0\n",
    "    if len(A[0]) == 0:\n",
    "        print(\"Empty matrix passed. Pass a finite matrix\")\n",
    "        return -1.0\n",
    "    \n",
    "    additions, multiplications, divisions, root = -1, 0, 0, 0\n",
    "    fro_norm = 0.0\n",
    "\n",
    "    for row in A:\n",
    "        for element in row:\n",
    "            fro_norm += element * element\n",
    "            additions += 1\n",
    "            multiplications += 1\n",
    "    \n",
    "    fro_norm = (fro_norm) ** 0.5\n",
    "    root += 1\n",
    "    return (fro_norm, (additions, multiplications, divisions, root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "**Convenience function to display a matrix A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_matrix(A):\n",
    "    \"\"\"\n",
    "    Convenience function to display a matrix in pretty formatting\n",
    "    \"\"\"\n",
    "    nr = len(A)\n",
    "    nc = len(A[0])\n",
    "    matrix_string = \"        \"\n",
    "    for col in range(nc):\n",
    "        matrix_string += f\"C{col+1:<7}\"\n",
    "    matrix_string += \"\\nR1   \"\n",
    "    for idx, r in enumerate(A):\n",
    "        for element in r:\n",
    "            matrix_string += f\"{element: .4f} \"\n",
    "        if idx < nr - 1:\n",
    "            matrix_string += f\"\\nR{idx + 2:<3} \"\n",
    "    print(matrix_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Requested matrix is square or wide; It must be tall. Please give m > n\n"
     ]
    }
   ],
   "source": [
    "# Try generating a random wide matrix\n",
    "# Expected Output: Error!\n",
    "A = create_random_matrix(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1      C2      C3      C4      \n",
      "R1    4.0136  0.9824  7.1691  8.0633 \n",
      "R2    7.4286  3.9179  5.7864  1.5765 \n",
      "R3    9.8305  6.7561  6.3717  3.2287 \n",
      "R4    8.1671  9.6811  5.3238  6.1795 \n",
      "R5    5.3595  0.4526  5.3378  0.0007 \n"
     ]
    }
   ],
   "source": [
    "# Try generating a tall matrix\n",
    "# Expected Output: A tall matrix\n",
    "A = create_random_matrix(5, 4)\n",
    "display_matrix(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius Norm of matrix A: 26.78938\n"
     ]
    }
   ],
   "source": [
    "# Try caluclating frobenius norm of generated matrix\n",
    "# Expected Output: A float\n",
    "n, _ = frob_norm(A)\n",
    "print(f\"Frobenius Norm of matrix A: {n:0.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "**ii** Write a code to decide if Gram-Schmidt Algorithm can be applied to columns of a given matrix A through calculation of rank. The code should print appropriate messages indicating whether Gram-Schmidt is applicable on columns of the matrix or not.\n",
    "\n",
    "> **Deliverable(s) : The code that performs the test. (1)**\n",
    "\n",
    "**Methodology**\n",
    "\n",
    "- Find the row reduced echelon form of the given matrix\n",
    "\n",
    "- If rank of the matrix = number of columns of A $\\Rightarrow$ A has LI columns $\\Rightarrow$ A can be decomposed into $QR$ form\n",
    "\n",
    "- If rank of matrix is less than number of columns of A, A has Linearly Dependent columns $\\Rightarrow$ A cannot be expressed as $QR$\n",
    "\n",
    "**PS**\n",
    "\n",
    "- To check if an element is zero in REF, we use a very small threshold value of 1e-6. Since computationally, we can get numbers very close to zero but not actually zero while performing row reduction; we are bound to take some small threshold value for near zero quantities.\n",
    "\n",
    "*Define some functions to perform elementary matrix operations i.e. inner product, vector addition and scalar multiplication, matrix multiplication, matrix transpose and eventually column normed matrix. These functions will also help us in later computations throughout the assignment*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "**Function to compute the inner product of two vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product(v1:List, v2:List) -> Tuple:\n",
    "    \"\"\"Given two vectors v1 and v2, computes their inner product\n",
    "\n",
    "    Args:\n",
    "        v1 (List): [A vector represented as a list]\n",
    "        v2 (List): [A vector represented as a list]\n",
    "\n",
    "    Returns:\n",
    "        Tuple: [A tuple of the inner product & number of additions, multiplications and divisions needed for performing the inner product]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Here initialize addition to -1 because to compute the inner product of two \n",
    "    # n dimensional vectors we only need n - 1 additions and n multiplications\n",
    "    additions, multiplications, divisions = -1, 0, 0\n",
    "    \n",
    "    dot_product = 0.0\n",
    "    for e1, e2 in zip(v1, v2):\n",
    "        dot_product += e1 * e2\n",
    "        additions += 1; multiplications += 1\n",
    "    \n",
    "    return (dot_product, (additions, multiplications, divisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "**Function to compute vector addition of two vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_addition(v1:List, v2:List) -> Tuple:\n",
    "    \"\"\"[Given two vectors, adds them and computes the number of +, -, / needed for the same]\n",
    "\n",
    "    Args:\n",
    "        v1 (List): [A vector represented as a list]\n",
    "        v2 (List): [A vector represented as a list]\n",
    "\n",
    "    Returns:\n",
    "        Tuple: [A tuple representing vector subtraction result and the number of +, -, / needed to compute the result]\n",
    "    \"\"\"\n",
    "    \n",
    "    additions, multiplications, divisions = 0, 0, 0\n",
    "    resultant = []\n",
    "    \n",
    "    for e1, e2 in zip(v1, v2):\n",
    "        resultant.append(e1 + e2)\n",
    "        additions += 1\n",
    "    \n",
    "    return (resultant, (additions, multiplications, divisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "**Function to compute scalar multiplication of a scalar with a vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_multiplication(v1:List, k: float) -> Tuple:\n",
    "    \"\"\"[Given a vector and a scalar, scales the vector appropriately]\n",
    "\n",
    "    Args:\n",
    "        v1 (List): [A vector represented as a list]\n",
    "        k (float): [A scalar]\n",
    "\n",
    "    Returns:\n",
    "        Tuple: [A tuple representing scalar multiplication result and the number of +, -, / needed to compute the result]\n",
    "    \"\"\"\n",
    "    \n",
    "    additions, multiplications, divisions = 0, 0, 0\n",
    "    resultant = []\n",
    "    \n",
    "    for e1 in v1:\n",
    "        resultant.append(k * e1)\n",
    "        multiplications += 1\n",
    "    \n",
    "    return (resultant, (additions, multiplications, divisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "**Function to perform matrix multiplication of two matrices A & B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_multiplication(A:List, B:List) -> Tuple:\n",
    "    \"\"\"[Given two matrices as list of lists, computes their matrix product]\n",
    "\n",
    "    Args:\n",
    "        A (List): [A matrix of dimension m x n]\n",
    "        B (List): [A matrix of dimension n x m]\n",
    "\n",
    "    Returns:\n",
    "        List: [A tuple of Matrix product as a list of lists and the number of additions, multiplications and divisions needed for performing the operation]\n",
    "    \"\"\"\n",
    "\n",
    "    a, m, d = 0, 0, 0\n",
    "\n",
    "    nrA, ncA = len(A), len(A[0])\n",
    "    nrB, ncB = len(B), len(B[0])\n",
    "\n",
    "    if ncA != nrB:\n",
    "        print(\"Matrix dimension mismatch, please input valid matrices\")\n",
    "        return ([], (a, m, d))\n",
    "    \n",
    "    B_columns = []\n",
    "    # Get a list of the columns of B\n",
    "    for c in range(ncB):\n",
    "        col = []\n",
    "        for r in range(nrB):\n",
    "            col.append(B[r][c])\n",
    "        B_columns.append(col)\n",
    "    \n",
    "    resultant_matrix = []\n",
    "    \n",
    "    # Iteratively multiply rows of A and columns of B in order to \n",
    "    # Compute the product A matmul B\n",
    "    for row in A:\n",
    "        resultant_row = []\n",
    "        for column in B_columns:\n",
    "            abij, (add, mult, div) = inner_product(row, column)\n",
    "            a += add; m += mult; d += div\n",
    "            resultant_row.append(abij)\n",
    "        resultant_matrix.append(resultant_row)\n",
    "    \n",
    "    return (resultant_matrix, (a, m, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "**Function to compute the transpose of a matrix A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_transpose(A:List) -> List:\n",
    "    \"\"\"[Given a matrix A, generate it's transpose]\n",
    "\n",
    "    Args:\n",
    "        A (List): [A matrix represented as list of lists]\n",
    "\n",
    "    Returns:\n",
    "        List: [Transpose of the matrix represented as list of lists]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the rows and columns of A\n",
    "    nr, nc = len(A), len(A[0])\n",
    "    \n",
    "    # Create a container for A_transpose\n",
    "    A_transpose = []\n",
    "\n",
    "    # Compute the transpose of A\n",
    "    for c in range(nc):\n",
    "        col = []\n",
    "        for r in range(nr):\n",
    "            col.append(A[r][c])\n",
    "        A_transpose.append(col)\n",
    "    \n",
    "    return A_transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "**Function to compute the column normalized version of a matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(A: List) -> Tuple:\n",
    "    \"\"\"[Given a matrix A, normalizes it's columns using l2-norm and returns the normalized matrix as a List of lists and also the number of +, -, /, sqrt needed for computing the result]\n",
    "    Args:\n",
    "        A (List): [Matrix represented as list of lists]\n",
    "    Returns:\n",
    "        Tuple: [A tuple of the normalized matrix and the count of +,-,/ needed for generating the matrix]\n",
    "    \"\"\"\n",
    "    # Initialize the number of additions, multiplications, divisions to zero\n",
    "    a, m, d, root = 0, 0, 0, 0\n",
    "\n",
    "    # If given matrix is a null matrix, return a null matrix\n",
    "    if len(A) == 0:\n",
    "        return ([], (a, m, d))\n",
    "    if len(A[0]) == 0:\n",
    "        return ([[]], (a, m, d))\n",
    "    \n",
    "    # Find the number of rows and columns of matrix A\n",
    "    nr, nc = len(A), len(A[0])\n",
    "    # First get the columns of A \n",
    "    A_columns = matrix_transpose(A)\n",
    "    # Compute the normed column matrix now\n",
    "    normalizedA = []\n",
    "\n",
    "    for col in A_columns:\n",
    "        dot_product, (add, mult, div) = inner_product(col, col)\n",
    "        a += add; m+= mult; d += div\n",
    "        \n",
    "        l2norm = (dot_product) ** 0.5\n",
    "        root += 1\n",
    "    \n",
    "        scaled_vector, (add, mult, div) = scalar_multiplication(col, 1 / l2norm)\n",
    "        # Since I have considered division ads multiplication with reciprocal here, I am adding the scaling multiplications to division count here\n",
    "        d += mult        \n",
    "        normalizedA.append(scaled_vector)\n",
    "        \n",
    "    # Get the matrix A in row major order again\n",
    "    normedARowMajor = matrix_transpose(normalizedA)   \n",
    "    return (normedARowMajor, (a, m, d, root))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "**Functions to move from flat nd vectors to a tall matrix of width 1 and vice versa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_column_matrix(m: List) -> List:\n",
    "    \"\"\"[Flatten a column matrix of n x 1 into an n-dimensional vector]\n",
    "\n",
    "    Args:\n",
    "        m (List): [A tall matrix of width 1]\n",
    "\n",
    "    Returns:\n",
    "        List: [A flattened vector]\n",
    "    \"\"\"\n",
    "    return [x[0] for x in m]\n",
    "\n",
    "def expand_column_vector(m: List) -> List:\n",
    "    \"\"\"[Convert a flat n-dimensional column vector into an n x 1 matrix]\n",
    "\n",
    "    Args:\n",
    "        m (List): [A flat nd vector]\n",
    "\n",
    "    Returns:\n",
    "        List: [A tall width=1 matrix]\n",
    "    \"\"\"\n",
    "    return [[x] for x in m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "**Now we will start with the real qn 1.ii by taking help of the functions defined above. Define a function to compute the row reduced echelon form of a matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rreduce(A:List, threshold:float = 1e-6) -> Tuple:\n",
    "    \"\"\"[Given a matrix A as a list of lists, compute it's row reduced echelon form.\n",
    "    Return that along with the rank of the matrix]\n",
    "\n",
    "    Args:\n",
    "        A (List): A m x n tall matrix\n",
    "        threshold (float, optional): When comparing the pivot elements, what magnitude of a value counts as zero magnitufe. Defaults to 1e-6.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: A tuple of row reduced echelon form and the decision i.e. whether\n",
    "        the matrix has linearly independent columns or not\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the number of additions, multiplications divisions to null\n",
    "    a, m, d = 0, 0, 0\n",
    "    \n",
    "    # Create a copy of the original matrix otherwise original\n",
    "    # matrix will get overwritten\n",
    "    A = copy.deepcopy(A)\n",
    "    \n",
    "    # Check if the matrix is empty\n",
    "    if len(A) == 0:\n",
    "        return ([], False)\n",
    "    if len(A[0]) == 0:\n",
    "        return ([[]], False)\n",
    "    \n",
    "    # Find out number of rows and columns\n",
    "    nr, nc = len(A), len(A[0])            \n",
    "    \n",
    "    # Get Echelon form using row reduction operations\n",
    "    # Only iterate for as many times as number of columns since \n",
    "    # tall matrix can't have more pivot elements than number of columns\n",
    "    for i in range(nc - 1):\n",
    "        \n",
    "        pivot_element = A[i][i]\n",
    "        \n",
    "        # Make all the elements below the pivot to be zero\n",
    "        # in an iterative manner\n",
    "        for j in range(i + 1, nr):\n",
    "                        \n",
    "            # Find the pivot element and compute the scaling factor\n",
    "            div_factor = A[j][i] / pivot_element     \n",
    "            d += 1\n",
    "            \n",
    "            # Scale the ith row based on the above factor\n",
    "            scaled_vector, (add, mult, div) = scalar_multiplication(A[i], -1 * div_factor)\n",
    "            a += add; m += mult; d += div;\n",
    "            \n",
    "            # Subtract the scaled row from A[j]\n",
    "            transformed_row, (add, mult, div) = vector_addition(A[j], scaled_vector)\n",
    "            \n",
    "            # Deduct the counts of add and mult by (i + 1) because when \n",
    "            # doing row reduction we are computing pivots in such a way \n",
    "            # that the elements below the pivot should become zeros \n",
    "            # and the elements to the left of the pivot are already zeros\n",
    "            # so no need to compute that term again and add it\n",
    "            add -= (i + 1); mult -= (i + 1);\n",
    "            a += add; m += mult; d += div;\n",
    "            \n",
    "            A[j] = transformed_row\n",
    "    \n",
    "    # Check the leading diagonal entries; I a few of them are zeros \n",
    "    # or near zeros, then given matrix has rank lower than nc(A)\n",
    "    col_rank = True\n",
    "    for i in range(nc):\n",
    "        if abs(A[i][i]) <= threshold:\n",
    "            col_rank = False\n",
    "            break\n",
    "                    \n",
    "    return (A, col_rank, (a, m, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1      C2      C3      C4      \n",
      "R1    7.1086  4.2724  3.6789  9.2282 \n",
      "R2    4.8841  9.3567  1.4473  4.8806 \n",
      "R3    1.2859  0.6668  9.9826  9.9426 \n",
      "R4    4.2317  9.9772  6.9267  1.1352 \n",
      "R5    7.0563  8.4662  8.1118  1.8957 \n"
     ]
    }
   ],
   "source": [
    "# Create a random tall matrix\n",
    "# Expected output: A tall matrix\n",
    "A = create_random_matrix(5,4)\n",
    "display_matrix(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1      C2      C3      C4      \n",
      "R1    7.1086  4.2724  3.6789  9.2282 \n",
      "R2    0.0000  6.4213 -1.0804 -1.4598 \n",
      "R3    0.0000  0.0000  9.2993  8.2492 \n",
      "R4    0.0000  0.0000  0.0000 -7.9796 \n",
      "R5    0.0000  0.0000  0.0000 -10.8910 \n",
      "\n",
      "Adds  required 20\n",
      "Mults required 20\n",
      "Divs  required 09\n",
      "\n",
      "A has linearly independent columns. Can apply GS Algorithm.\n"
     ]
    }
   ],
   "source": [
    "# Row reduce the matrix into it's REF and see if it's columns are linearly independent\n",
    "# Expected output: REF of generated matrix, primitive operations count, whether cols are LI\n",
    "ref, dec, (a, m ,d) = rreduce(A)\n",
    "display_matrix(ref)\n",
    "print(f\"\\nAdds  required {a:02d}\\nMults required {m:02d}\\nDivs  required {d:02d}\\n\")\n",
    "if dec == True:\n",
    "    print(f\"A has linearly independent columns. Can apply GS Algorithm.\")\n",
    "else:\n",
    "    print(f\"A has linearly dependent columns. Cannot apply GS Algorithm.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purposely generate a matrix where rows are linearly dependent\n",
    "# And check if the GS Algorithm can be applied to this matrix\n",
    "# Expected output: r < nc => Cannot apply GS Algorithm\n",
    "r1 = [generate_random_entry() for i in range(3)]\n",
    "r2 = [generate_random_entry() for i in range(3)]\n",
    "r3 = [0.1*(x + y) for x, y  in zip(r1, r2)]\n",
    "r4 = [(x - y)/2 for x, y in zip(r2, r3)]\n",
    "A = [r1,r2,r3,r4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1      C2      C3      \n",
      "R1    0.0477  8.9017  5.6728 \n",
      "R2    8.2004  7.0484  8.8143 \n",
      "R3    0.8248  1.5950  1.4487 \n",
      "R4    3.6878  2.7267  3.6828 \n"
     ]
    }
   ],
   "source": [
    "display_matrix(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1      C2      C3      \n",
      "R1    0.0477  8.9017  5.6728 \n",
      "R2    0.0000 -1523.2975 -966.4316 \n",
      "R3    0.0000  0.0000  0.0000 \n",
      "R4    0.0000  0.0000 -0.0000 \n",
      "\n",
      "Adds  required 08\n",
      "Mults required 08\n",
      "Divs  required 05\n",
      "\n",
      "A has linearly dependent columns. Cannot apply GS Algorithm.\n"
     ]
    }
   ],
   "source": [
    "# Row reduce the matrix into it's REF and see if it's \n",
    "# columns are linearly independent\n",
    "# Expected output: REF of generated matrix, primitive\n",
    "# operations count, whether cols are LI\n",
    "ref, dec, (a, m ,d) = rreduce(A)\n",
    "display_matrix(ref)\n",
    "print(f\"\\nAdds  required {a:02d}\\nMults required {m:02d}\\nDivs  required {d:02d}\\n\")\n",
    "if dec == True:\n",
    "    print(f\"A has linearly independent columns. Can apply GS Algorithm.\")\n",
    "else:\n",
    "    print(f\"A has linearly dependent columns. Cannot apply GS Algorithm.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "**iii**: Write a code to generate the orthogonal matrix Q from a matrix A by performing the Gram-Schmidt orthogonalization method. Ensure that A has linearly independent columns by checking the rank. Keep generating A until the linear independence is obtained.\n",
    "\n",
    "> **Deliverable(s) : The code that produces matrix Q from A (1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_schmidt_orthogonalization(A: List) -> Tuple:\n",
    "    \"\"\"[Given a matrix A, checks if it's columns are Linearly Independent and if yes, generates an orthogonal matrix from the same]\n",
    "\n",
    "    Args:\n",
    "        A (List): [Matrix represented as list of lists]\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (A tuple representing whether A contains linearly independent columns and if yes, an orthogonal matrix generated from A)\n",
    "    \"\"\"\n",
    "    \n",
    "    # If the vector is null then simply return\n",
    "    if len(A) == 0:\n",
    "        return (False, [])\n",
    "    if len(A[0]) == 0:\n",
    "        return (False, [[]])\n",
    "    \n",
    "    # Compute the number of rows and columns of matrix A\n",
    "    nr, nc = len(A), len(A[0])\n",
    "    A_columns = matrix_transpose(A)\n",
    "    \n",
    "    # Check if A has linearly independent columns or not\n",
    "    # If no, then cannot apply GS Algorithm\n",
    "    ref, dec, _ = rreduce(A)\n",
    "    if not dec:\n",
    "        return (False, [])\n",
    "    print(f\"\\nThe given matrix A has linearly independent columns.\\nHence we can compute Gram-Schmidt Orthogonalization\\n\\nREF of given matrix as follows\\n\") \n",
    "    display_matrix(ref)\n",
    "    \n",
    "    # Start generating an orthogonal basis for A\n",
    "    v = []\n",
    "    vi_inner_product = []\n",
    "\n",
    "    # Initialize the addition, multiplication and division counts to zeros\n",
    "    additions, multiplications, divisions = 0, 0, 0\n",
    "    \n",
    "    # Iterate over the columns of A\n",
    "    for n in range(nc):\n",
    "\n",
    "        xi = A_columns[n]\n",
    "        vi = xi\n",
    "        \n",
    "        for it in range(n):\n",
    "            \n",
    "            # Compute xi.vi inner product\n",
    "            xivi, (a, m, d) = inner_product(xi, v[it])\n",
    "            additions += a; multiplications += m; divisions += d\n",
    "            \n",
    "            # Check if vi's inner product exists\n",
    "            if it < (len(vi_inner_product)):\n",
    "                vivi = vi_inner_product[it]\n",
    "            else:\n",
    "                vivi, (a, m, d) = inner_product(v[-1], v[-1])\n",
    "                additions += a; multiplications += m; divisions += d\n",
    "                vi_inner_product.append(vivi)\n",
    "            \n",
    "            scaling_factor = -1 * xivi / vivi\n",
    "            divisions += 1\n",
    "            \n",
    "            scaled_vector, (a, m, d) = scalar_multiplication(v[it], scaling_factor)\n",
    "            additions += a; multiplications += m; divisions += d\n",
    "\n",
    "            vi, (a, m, d) = vector_addition(vi, scaled_vector)\n",
    "            additions += a; multiplications += m; divisions += d\n",
    "        \n",
    "        v.append(vi)\n",
    "    \n",
    "    # Reframe the matrix in row major order\n",
    "    O = matrix_transpose(v)\n",
    "        \n",
    "    return (O, (additions, multiplications, divisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly Generated Matrix\n",
      "        C1      C2      C3      C4      \n",
      "R1    0.1008  6.3822  1.9332  0.8202 \n",
      "R2    6.0748  0.3064  4.5908  3.9357 \n",
      "R3    4.5107  5.5223  5.5853  0.1209 \n",
      "R4    2.4546  7.3966  5.1188  9.1374 \n",
      "R5    4.0419  4.1145  0.8893  0.7767 \n",
      "\n",
      "The given matrix A has linearly independent columns.\n",
      "Hence we can compute Gram-Schmidt Orthogonalization\n",
      "\n",
      "REF of given matrix as follows\n",
      "\n",
      "        C1      C2      C3      C4      \n",
      "R1    0.1008  6.3822  1.9332  0.8202 \n",
      "R2    0.0000 -384.3225 -111.9152 -45.4944 \n",
      "R3    0.0000  0.0000  0.6347 -3.4282 \n",
      "R4    0.0000  0.0000  0.0000  12.8764 \n",
      "R5    0.0000  0.0000  0.0000 -20.1520 \n",
      "\n",
      "Linearly independent cols obtained from GSO procedure\n",
      "        C1      C2      C3      C4      \n",
      "R1    0.1008  6.3035 -0.2832 -1.5646 \n",
      "R2    6.0748 -4.4392  0.7921  1.1892 \n",
      "R3    4.5107  1.9986  0.9768 -4.4586 \n",
      "R4    2.4546  5.4791  1.1281  4.2801 \n",
      "R5    4.0419  0.9570 -2.9587  0.6281 \n"
     ]
    }
   ],
   "source": [
    "# Create a random matrix A and compute normalize their cols using gram schmidt orthogonalization procedure\n",
    "# Expected output: The matrix and it's gram-schmidt orthogonalization matrix\n",
    "x = create_random_matrix(5, 4)\n",
    "print(\"Randomly Generated Matrix\")\n",
    "display_matrix(x)\n",
    "v, (a, m, d) = gram_schmidt_orthogonalization(x)\n",
    "\n",
    "if v:\n",
    "    print(f\"\\nLinearly independent cols obtained from GSO procedure\")\n",
    "    display_matrix(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "**iv**: Write a code to create a QR decomposition of the matrix A by utilizing the code developed in the previous sub-parts of this question. Find the matrices Q and R and then display the value $||A - (QR)||_F$ , where $||\\cdot||_F$ is the Frobenius norm. The code should also display the total number of additions, multiplications and divisions to find the result.\n",
    "\n",
    "> **Deliverable(s) : The code with the said input and output. The results obtained for A generated with m = 7 and n = 5 with random entries described above. (2.5)**\n",
    "\n",
    "**Methodology**\n",
    "\n",
    "Computing gram-schmidt orthogonalization requires several steps as follows\n",
    "\n",
    "- Verify A has LI columns $\\Rightarrow$ Compute the REF and ascertain $Rank = nc(A)$\n",
    "\n",
    "- If above condition is met, orthogonalize the columns of matrix A using GS algorithm\n",
    "\n",
    "- Normalize columns of the orthogonal matrix obtained above\n",
    "\n",
    "- $A = QR \\Rightarrow Q^{-1}A = Q^{-1}QR \\Rightarrow R = Q^TA \\because Q^{-1} = Q^T \\text{as Q is orthonormal}$\n",
    "\n",
    "- Compute the matrix product $Q^TA$ to find $R$.\n",
    "\n",
    "- Find out the primitive counts at each step of the procedure and report them individually and the totals as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly Generated Matrix\n",
      "        C1      C2      C3      C4      C5      \n",
      "R1    6.1365  1.0361  3.1545  1.4542  8.8476 \n",
      "R2    1.7695  8.5708  0.7573  7.0305  4.9097 \n",
      "R3    0.8503  6.3664  4.6884  5.4526  6.5478 \n",
      "R4    8.4884  6.9733  6.8779  9.2543  5.7732 \n",
      "R5    0.9465  2.4735  1.7498  3.5662  7.8038 \n",
      "R6    8.7554  8.0415  1.0145  4.4992  8.9681 \n",
      "R7    2.1917  5.6678  1.7968  0.5019  0.2328 \n",
      "\n",
      "The given matrix A has linearly independent columns.\n",
      "Hence we can compute Gram-Schmidt Orthogonalization\n",
      "\n",
      "REF of given matrix as follows\n",
      "\n",
      "        C1      C2      C3      C4      C5      \n",
      "R1    6.1365  1.0361  3.1545  1.4542  8.8476 \n",
      "R2   -0.0000  8.2720 -0.1523  6.6112  2.3584 \n",
      "R3    0.0000  0.0000  4.3659  0.2777  3.5476 \n",
      "R4    0.0000 -0.0000  0.0000  2.6486 -10.1710 \n",
      "R5    0.0000  0.0000  0.0000  0.0000  10.1318 \n",
      "R6    0.0000  0.0000  0.0000  0.0000 -12.8033 \n",
      "R7    0.0000 -0.0000  0.0000  0.0000 -21.5755 \n",
      "\n",
      "Matrix Q\n",
      "        C1      C2      C3      C4      C5      \n",
      "R1    0.4384 -0.4005  0.1776 -0.1877  0.4752 \n",
      "R2    0.1264  0.6498 -0.2817  0.4076  0.0003 \n",
      "R3    0.0607  0.5202  0.5315 -0.1801  0.2836 \n",
      "R4    0.6064 -0.0415  0.4766  0.3130 -0.5265 \n",
      "R5    0.0676  0.1523  0.1608  0.2503  0.5925 \n",
      "R6    0.6255  0.0357 -0.5945 -0.0699  0.1395 \n",
      "R7    0.1566  0.3471 -0.0166 -0.7750 -0.2146 \n",
      "\n",
      "Matrix R\n",
      "        C1      C2      C3      C4      C5      \n",
      "R1    13.9971  12.2382  6.9688  10.6038  14.5722 \n",
      "R2    0.0000  10.8086  2.3087  7.3169  4.4033 \n",
      "R3   -0.0000 -0.0000  5.7651  3.4768  2.3398 \n",
      "R4    0.0000  0.0000  0.0000  4.6971  2.1153 \n",
      "R5    0.0000 -0.0000  0.0000 -0.0000  8.8477 \n",
      "\n",
      "Matrix (A - QR)\n",
      "        C1      C2      C3      C4      C5      \n",
      "R1    0.0000  0.0000  0.0000  0.0000  0.0000 \n",
      "R2   -0.0000 -0.0000 -0.0000 -0.0000  0.0000 \n",
      "R3    0.0000  0.0000  0.0000  0.0000 -0.0000 \n",
      "R4    0.0000  0.0000  0.0000 -0.0000  0.0000 \n",
      "R5   -0.0000  0.0000 -0.0000  0.0000 -0.0000 \n",
      "R6   -0.0000 -0.0000 -0.0000 -0.0000 -0.0000 \n",
      "R7    0.0000  0.0000  0.0000  0.0000 -0.0000 \n",
      "\n",
      "Frobenius norm of (A - QR) = 0.00000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Additions</th>\n",
       "      <th>Multiplications</th>\n",
       "      <th>Divisions</th>\n",
       "      <th>Square Root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>REF</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS Algorithm</th>\n",
       "      <td>154</td>\n",
       "      <td>168</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orthonormalization</th>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R = Q'A Computation</th>\n",
       "      <td>150</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(A - QR) Computation</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norm(A - QR) Computation</th>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Count</th>\n",
       "      <td>453</td>\n",
       "      <td>463</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Additions  Multiplications  Divisions  Square Root\n",
       "REF                              50               50         18            0\n",
       "GS Algorithm                    154              168         10            0\n",
       "Orthonormalization               30               35         35            5\n",
       "R = Q'A Computation             150              175          0            0\n",
       "(A - QR) Computation             35                0          0            0\n",
       "Norm(A - QR) Computation         34               35          0            1\n",
       "Total Count                     453              463         63            6"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random matrix\n",
    "A = create_random_matrix(7, 5)\n",
    "\n",
    "# Display the matrix generated\n",
    "print(\"\\nRandomly Generated Matrix\")\n",
    "display_matrix(A)\n",
    "\n",
    "# Compute REF of the matrix and count the number of primitive operations incurred in the same\n",
    "ref, decision, (aref, mref, dref) = rreduce(A)\n",
    "\n",
    "if decision:\n",
    "    # Apply GS Algorithm to find an orthogonal basis\n",
    "    v, (ags, mgs, dgs) = gram_schmidt_orthogonalization(A)\n",
    "\n",
    "    # Make the orthogonal basis into an orthonormal one\n",
    "    Q, (anorm, mnorm, dnorm, rootnorm) = normalize_columns(v)\n",
    "    \n",
    "    # Compute the matrix R using the orthonormal matrix and the original matrix\n",
    "    R, (aR, mR, dR) = matrix_multiplication(matrix_transpose(Q), A)\n",
    "    \n",
    "    # Compute the matrix QR\n",
    "    QR, (aQR, mQR, dQR) = matrix_multiplication(Q, R)\n",
    "    \n",
    "    # Compute the matrix A - QR\n",
    "    delta = []\n",
    "    addDelta, multDelta, divDelta = 0, 0, 0\n",
    "    for a_row, qr_row in zip(A, QR):\n",
    "        scaled_vector, _ = scalar_multiplication(qr_row, -1)\n",
    "        resultant, (a, m, d) = vector_addition(a_row, scaled_vector)\n",
    "        addDelta += a; multDelta += m; divDelta += d\n",
    "        delta.append(resultant)\n",
    "    \n",
    "    # Compute the frobenius norm of A - QR = delta\n",
    "    fn, (afro, mfro, divfro, rootfro) = frob_norm(delta)\n",
    "    \n",
    "    \n",
    "    # Display the matrices Q, R and A - QR respectively\n",
    "    print(f\"\\nMatrix Q\")\n",
    "    display_matrix(Q)\n",
    "    print(f\"\\nMatrix R\")\n",
    "    display_matrix(R)\n",
    "    print(f\"\\nMatrix (A - QR)\")\n",
    "    display_matrix(delta)\n",
    "    print(f\"\\nFrobenius norm of (A - QR) = {fn:.5f}\")\n",
    "    \n",
    "    \n",
    "    # Find out the counts for each and every step along the way\n",
    "    total_additions = aref + ags + anorm + aR + addDelta + afro \n",
    "    total_multiplications = mref + mgs + mnorm + mR + multDelta + mfro\n",
    "    total_divisions = dref + dgs + dnorm + dR + divDelta + divfro\n",
    "    total_sqrts = rootnorm + rootfro\n",
    "    \n",
    "    count_matrix = [(aref, mref, dref, 0), (ags, mgs, dgs, 0), (anorm, mnorm, dnorm, rootnorm), (aR, mR, dR, 0), (addDelta, multDelta, divDelta, 0), (afro, mfro, divfro, rootfro), (total_additions, total_multiplications, total_divisions, total_sqrts)]\n",
    "    \n",
    "    import pandas as pd\n",
    "    count_df = pd.DataFrame(count_matrix, index = [\"REF\", \"GS Algorithm\", \"Orthonormalization\", \"R = Q'A Computation\", \"(A - QR) Computation\", \"Norm(A - QR) Computation\", \"Total Count\"], columns = [\"Additions\", \"Multiplications\", \"Divisions\", \"Square Root\"])\n",
    "count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: Gradient Descent Algorithm\n",
    "\n",
    "**i**: Consider the last 4 digits of your mobile number (Note : In case there is a 0 in one of the digits replace it by 3). Let it be $n_1n_2n_3n_4$. Generate a random matrix A of size $n_1n_2 \\times n_3n_4$. For example, if the last four digits are 2311, generate a random matrix of size 23 × 11. Write a code to calculate the $l_{\\infty}$ norm of this matrix.\n",
    "\n",
    "> **Deliverable(s) : The code that generates the results. (0.5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gradient_descent_matrix() -> Tuple:\n",
    "    \"\"\"[Creates a matrix of the size n1n2 * n3n4 and a matrix b of size n1n2 * 1]\n",
    "\n",
    "    Returns:\n",
    "        List: A matrix in the form of a list\n",
    "    \"\"\"\n",
    "\n",
    "    # Prompt the user for his mobile number\n",
    "    \n",
    "    # Ascertain the mobile number is valid\n",
    "    number = input(\"Enter your phone number:\\n\")\n",
    "    try:\n",
    "        n = int(number)\n",
    "        if len(number.strip()) != 10:\n",
    "            print(\"Mobile number must have exactly 10 digits. Please enter a valid number\")\n",
    "            return ([], [])\n",
    "    except Exception as e:\n",
    "        print(f\"{str(e)}\\nEntered number invalid. Please enter a valid number\")\n",
    "        return ([], [])\n",
    "    \n",
    "    # Get the last 4 digits of the number and replace\n",
    "    # 0s in the number with 3s\n",
    "    rc = number.strip()[-4:]\n",
    "    rc = rc.replace(\"0\", \"3\")\n",
    "\n",
    "    nr, nc = int(rc[:2]), int(rc[2:])\n",
    "    matrix = create_random_matrix(nr, nc, wide = True)\n",
    "    b = create_random_matrix(nr, 1, wide = True)\n",
    "    \n",
    "    return (matrix, b)\n",
    "\n",
    "def linf_norm(matrix: List) -> float:\n",
    "    \"\"\"[Given a matrix computes it's linfinity norm]\n",
    "\n",
    "    Args:\n",
    "        matrix (List): [Matrix represented as a list of numbers]\n",
    "\n",
    "    Returns:\n",
    "        float: The infinity norm of the said matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    inf_norm = 0\n",
    "\n",
    "    # For each row in the matrix\n",
    "    for row in matrix:\n",
    "        rsum = 0\n",
    "\n",
    "        # Compute the row sum of absolute vals of elements in that row\n",
    "        for element in row:\n",
    "            rsum += abs(element)\n",
    "\n",
    "        # Store the largest row sum\n",
    "        if rsum > inf_norm:\n",
    "            inf_norm = rsum\n",
    "    return inf_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your phone number:\n",
      " sdfdsf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid literal for int() with base 10: 'sdfdsf'\n",
      "Entered number invalid. Please enter a valid number\n"
     ]
    }
   ],
   "source": [
    "# Create the gradient descent matrices A & b. \n",
    "# Validate the input to have a proper mobile number\n",
    "A, b = generate_gradient_descent_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your phone number:\n",
      " 6464568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile number must have exactly 10 digits. Please enter a valid number\n"
     ]
    }
   ],
   "source": [
    "# Create the gradient descent matrices A & b. \n",
    "# Validate the input to have a proper mobile number\n",
    "A, b = generate_gradient_descent_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your phone number:\n",
      " 773868556846845654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile number must have exactly 10 digits. Please enter a valid number\n"
     ]
    }
   ],
   "source": [
    "# Create the gradient descent matrices A & b. \n",
    "# Validate the input to have a proper mobile number\n",
    "A, b = generate_gradient_descent_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your phone number:\n",
      " 7738368566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L-inf norm of the generated matrix A is 380.58060\n"
     ]
    }
   ],
   "source": [
    "# Create the gradient descent matrices A & b. \n",
    "# Validate the input to have a proper mobile number\n",
    "A, b = generate_gradient_descent_matrix()\n",
    "print(f\"L-inf norm of the generated matrix A is {linf_norm(A):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii** Generate a random vector b of size $n_1n_2 \\times 1$ and consider the function $f(x) = \\frac{1}{2}||Ax - b||_2^2$ where $|| \\cdot ||_2$ is the vector $l_2$ norm. Its gradient is given to be $\\nabla f(x) = A^TAx - A^Tb$. Write a code to find the local minima of this function by using the gradient descent algorithm (by using the gradient expression given to you). The step size $\\tau$ in the iteration $x_k + 1 = x_k − \\tau \\nabla f(x_k)$ should be chosen by the formula \n",
    "\n",
    "$$\n",
    "\\tau = \\frac{g_k^Tg_k}{g_k^TA^TAg_k}\n",
    "$$\n",
    "\n",
    "where $g_k = \\nabla f(x_k) = A^TAx_k - A^Tb$ The algorithm should execute\n",
    "until $||x_k - x_{k - 1}||_2 < 10^{-4}$.\n",
    "\n",
    "> **Deliverable(s) : The code that finds the minimum of the given function and the expression for $\\tau$. The values of $x_k$ and $f(x_k)$ should be stored in a file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "def gradient_descent(stopping_threshold:float = 1e-4) -> List:\n",
    "    \"\"\"[Generates a random matrix based on user's mobile number, performs gradient descent and returns the solutions of the system of equation and intermediate steps taken]\n",
    "    \n",
    "    Args:\n",
    "        stopping_threshold (float): [When to stop iterating, i.e. convergence criterion]\n",
    "        \n",
    "    Returns:\n",
    "        List: [A list of solutions, intermediate values and function values at each step]\n",
    "    \"\"\"\n",
    "    \n",
    "    A, b = generate_gradient_descent_matrix()\n",
    "    n_equations, n_features = len(A), len(A[0])\n",
    "    \n",
    "    # Start with an initial guess of all zeros\n",
    "    current_solution = [[0.0] for r in range(n_features)]\n",
    "    optimization_steps = []\n",
    "\n",
    "    # Begin optimization here\n",
    "    while True:\n",
    "        \n",
    "        # Find out the function value\n",
    "        result = matrix_multiplication(A, current_solution)[0]\n",
    "        scaled_b = scalar_multiplication(flatten_column_matrix(b), -1)[0]\n",
    "        f = vector_addition(flatten_column_matrix(result), scaled_b)[0]\n",
    "        fn = frob_norm(expand_column_vector(f))[0]\n",
    "        func_val = 0.5 * (fn ** 2)\n",
    "        \n",
    "\n",
    "        # Find the gradient of the function at the current step \n",
    "        # i. Find AtAx\n",
    "        A_transpose = matrix_transpose(A)\n",
    "        AtA = matrix_multiplication(A_transpose, A)[0]\n",
    "        AtAx = matrix_multiplication(AtA, current_solution)[0]\n",
    "        \n",
    "        # ii. Find Atb\n",
    "        Atb = matrix_multiplication(A_transpose, b)[0]\n",
    "        \n",
    "        # iii. Find AtAx - Atb\n",
    "        scaled_Atb = scalar_multiplication(flatten_column_matrix(Atb), -1)[0]\n",
    "        gradf = vector_addition(flatten_column_matrix(AtAx), scaled_Atb)[0]\n",
    "        gradf = expand_column_vector(gradf)\n",
    "        \n",
    "        # Compute the learning rate\n",
    "        gradf_transpose = matrix_transpose(gradf)\n",
    "        tau_nr = matrix_multiplication(gradf_transpose, gradf)[0][0][0]\n",
    "        tau_dr = matrix_multiplication(gradf_transpose, matrix_multiplication(AtA, gradf)[0])[0][0][0]\n",
    "        # To avoid numerical instability, add a very tiny epsilon to the denominator\n",
    "        learning_rate = tau_nr / (tau_dr + 1e-16)\n",
    "        \n",
    "        # Take a step in the opposite direction of the gradient\n",
    "        previous_solution = current_solution\n",
    "        scaled_gradf = scalar_multiplication(flatten_column_matrix(gradf), -1 * learning_rate)[0]\n",
    "        current_solution = vector_addition(flatten_column_matrix(previous_solution), scaled_gradf)[0]\n",
    "        current_solution = expand_column_vector(current_solution)\n",
    "        \n",
    "        # Define the stopping criterion\n",
    "        scaled_prev_sol = scalar_multiplication(flatten_column_matrix(previous_solution), -1)[0]\n",
    "        step_delta = vector_addition(flatten_column_matrix(current_solution), scaled_prev_sol)[0]\n",
    "        \n",
    "        stopping_threshold = frob_norm(expand_column_vector(step_delta))[0]\n",
    "        if abs(stopping_threshold) <= 1e-4:\n",
    "            break\n",
    "\n",
    "        optimization_steps.append([previous_solution, gradf, func_val])\n",
    "    \n",
    "    return optimization_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your phone number:\n",
      " 7738368566\n"
     ]
    }
   ],
   "source": [
    "# Perform gradient descent by prompting the user for phone number and store the result obtained in a \n",
    "# CSV file with the points, gradients and the function value at that point \n",
    "solutions = gradient_descent()\n",
    "df = pd.DataFrame(solutions, columns = [\"Point\", \"Gradient\", \"FunctionValue\"])\n",
    "\n",
    "# Save the obtained solutions to a file\n",
    "df.to_csv(\"solutions.csv\", index = None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point</th>\n",
       "      <th>Gradient</th>\n",
       "      <th>FunctionValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>[[-0.058967398210707546], [-0.29632870331270006], [-0.06463032397153941], [0.14936638936556615], [-0.24987774610441515], [0.20210566625648033], [0.10184743851017858], [-0.22160922062986746], [0.20055007880918474], [0.3289383427587664], [0.141392535836497], [-0.44350072380033456], [-0.18111446447898286], [0.24642767836215634], [-0.3944546083909666], [0.1467534984914903], [0.4675588258095588], [0.3252020621867888], [0.3299141159915386], [-0.3332965944639392], [0.28598199485776604], [0.31978213391519417], [-0.13268685320940257], [0.17693609426483964], [0.13859029846985274], [0.06470600296051265], [0.47631274447239597], [-0.08279485978498942], [0.11258563678385788], [0.1828316499463245], [-0.19473941767126318], [0.028444117828948668], [-0.03254736489024182], [0.06806189441890936], [-0.12368326010262692], [-0.2307638432944469], [0.07709391209079744], [-0.2368353261101296], [0.14615512326239088], [-0.03394216422980806], [-0.1655697046539449], [0.2322539318983307], [0.012894801465627216], [0.1498778931993199], [-0.12884364750899932], [0.018887738158668618], [0.34897401642222303], [-0.21849820307692883], [-0.22612384071201666], [0.15641181754548772], [-0.32547590762035267], [-0.04594696162949528], [-0.024983541064229658], [0.14901791055719077], [-0.12080298093259675], [0.07432625974871765], [0.19095095177048632], [-0.019589520425997257], [-0.17292497255652967], [0.25530005424931185], [-0.096925359766372], [0.048608965877388874], [-0.37795910797377186], [-0.12378345174376727], [0.0821267159310158], [-0.07180691877609308]]</td>\n",
       "      <td>[[0.14987355737093822], [0.3190519787970061], [0.0031789979470886465], [-0.22348092368611105], [0.40386463260711025], [0.005723363016159055], [0.08862092308254432], [0.03344068511023579], [0.2002370663565216], [-0.04880435346831291], [-0.03214700218768485], [-0.25060947769929953], [0.030489286958527373], [-0.38325802862755154], [0.3871532369603301], [0.3179608184927929], [-0.11573679263165104], [-0.20208887043236246], [-0.403722606278734], [0.5032624861912609], [0.021180348755478917], [-0.200022555954547], [0.1962333510668941], [0.1443904717834812], [-0.3116018283001267], [-0.17014126089134152], [-0.4437406785973508], [0.17482804455994483], [-0.22918629024479742], [0.24744190838327995], [-0.002368362460629214], [0.13264312105138742], [0.21985304067175093], [0.08036345856862681], [-0.1302626618225986], [0.3731468295909508], [-0.11291401193125239], [-0.025925709338707748], [-0.07773066248660143], [-0.005108987897529005], [0.3008771451281973], [-0.05178424772793733], [0.29850627973428345], [0.09334912431268094], [-0.010753229481906601], [0.30842921667090195], [-0.0901372814446404], [-0.07407848558727892], [-0.03678351562507487], [-0.2542470956809666], [0.11317676900102924], [-0.19882629058338352], [0.0710152086612652], [0.3432616420377599], [0.23845257313087131], [-0.023361311719781952], [-0.2718671387090126], [0.03311537920603769], [0.35672442676377614], [-0.1623819362548602], [0.14124096110981554], [0.1437222851777733], [-0.014136401038058466], [0.21786917773897585], [-0.2426264299660943], [-0.03605034635938864]]</td>\n",
       "      <td>81.212115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Point  \\\n",
       "681  [[-0.058967398210707546], [-0.29632870331270006], [-0.06463032397153941], [0.14936638936556615], [-0.24987774610441515], [0.20210566625648033], [0.10184743851017858], [-0.22160922062986746], [0.20055007880918474], [0.3289383427587664], [0.141392535836497], [-0.44350072380033456], [-0.18111446447898286], [0.24642767836215634], [-0.3944546083909666], [0.1467534984914903], [0.4675588258095588], [0.3252020621867888], [0.3299141159915386], [-0.3332965944639392], [0.28598199485776604], [0.31978213391519417], [-0.13268685320940257], [0.17693609426483964], [0.13859029846985274], [0.06470600296051265], [0.47631274447239597], [-0.08279485978498942], [0.11258563678385788], [0.1828316499463245], [-0.19473941767126318], [0.028444117828948668], [-0.03254736489024182], [0.06806189441890936], [-0.12368326010262692], [-0.2307638432944469], [0.07709391209079744], [-0.2368353261101296], [0.14615512326239088], [-0.03394216422980806], [-0.1655697046539449], [0.2322539318983307], [0.012894801465627216], [0.1498778931993199], [-0.12884364750899932], [0.018887738158668618], [0.34897401642222303], [-0.21849820307692883], [-0.22612384071201666], [0.15641181754548772], [-0.32547590762035267], [-0.04594696162949528], [-0.024983541064229658], [0.14901791055719077], [-0.12080298093259675], [0.07432625974871765], [0.19095095177048632], [-0.019589520425997257], [-0.17292497255652967], [0.25530005424931185], [-0.096925359766372], [0.048608965877388874], [-0.37795910797377186], [-0.12378345174376727], [0.0821267159310158], [-0.07180691877609308]]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Gradient  \\\n",
       "681  [[0.14987355737093822], [0.3190519787970061], [0.0031789979470886465], [-0.22348092368611105], [0.40386463260711025], [0.005723363016159055], [0.08862092308254432], [0.03344068511023579], [0.2002370663565216], [-0.04880435346831291], [-0.03214700218768485], [-0.25060947769929953], [0.030489286958527373], [-0.38325802862755154], [0.3871532369603301], [0.3179608184927929], [-0.11573679263165104], [-0.20208887043236246], [-0.403722606278734], [0.5032624861912609], [0.021180348755478917], [-0.200022555954547], [0.1962333510668941], [0.1443904717834812], [-0.3116018283001267], [-0.17014126089134152], [-0.4437406785973508], [0.17482804455994483], [-0.22918629024479742], [0.24744190838327995], [-0.002368362460629214], [0.13264312105138742], [0.21985304067175093], [0.08036345856862681], [-0.1302626618225986], [0.3731468295909508], [-0.11291401193125239], [-0.025925709338707748], [-0.07773066248660143], [-0.005108987897529005], [0.3008771451281973], [-0.05178424772793733], [0.29850627973428345], [0.09334912431268094], [-0.010753229481906601], [0.30842921667090195], [-0.0901372814446404], [-0.07407848558727892], [-0.03678351562507487], [-0.2542470956809666], [0.11317676900102924], [-0.19882629058338352], [0.0710152086612652], [0.3432616420377599], [0.23845257313087131], [-0.023361311719781952], [-0.2718671387090126], [0.03311537920603769], [0.35672442676377614], [-0.1623819362548602], [0.14124096110981554], [0.1437222851777733], [-0.014136401038058466], [0.21786917773897585], [-0.2426264299660943], [-0.03605034635938864]]   \n",
       "\n",
       "     FunctionValue  \n",
       "681      81.212115  "
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii** Generate the graph of $f(x_k)$ vs $k$ where $k$ is the iteration number and $x_k$ is the current estimate of $x$ at iteration $k$. This graph should convey the decreasing nature of function values.\n",
    "\n",
    "> **Deliverable(s) : The graph that is generated.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "fig, ax = plt.subplots(1, 1, figsize = (15,4))\n",
    "\n",
    "plt.plot(df.index.tolist(), df.FunctionValue, )\n",
    "plt.xlabel(\"Iteration Number\", fontsize = 20)\n",
    "plt.ylabel(\"Function Value\", fontsize = 20)\n",
    "plt.title(\"Gradient Descent Optimization Plot\", fontsize = 20);\n",
    "plt.xlim([-10,700]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critical points of polynomial function\n",
    "\n",
    "**i** Generate a third degree polynomial in $x$ and $y$ named $g(x,y)$ that is based on your mobile number (Note : In case there is a 0 in one of the\n",
    "digits replace it by 3). Suppose your mobile number is $9412821233$, then the polynomial would be \n",
    "\n",
    "$$ \n",
    "g(x,y) = 9x^3 - 4x^2y + 1xy^2 -2y^3 +8x^2 -2xy + 1y^2 -2x + 3y -3\n",
    "$$\n",
    "\n",
    "where alternate positive and negative sign are used. \n",
    "\n",
    "> **Deliverable(s) : The polynomial constructed should be reported. (0.5)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```octave\n",
    "## Author: vinayak <vinayak@vinayak-EXIGO-V2>\n",
    "## Created: 2022-02-21\n",
    "% Script to read a phone number and create a polynomial \n",
    "\n",
    "function [pol] = qn31()\n",
    "  a = input(\"Enter your mobile number\\n\");\n",
    "  % Allocate memory for the polynomial to be created\n",
    "  pol = []; \n",
    "  num = a;\n",
    "  counter = 1;\n",
    "  \n",
    "  % Parse through the input number and then convert them \n",
    "  % into a vector of values in sequential manner\n",
    "  % Alternate +ve and -ve signs for co-efficients\n",
    "  % If a zero is present in the number, substitute it with +-3\n",
    "  while num > 1,\n",
    "    \n",
    "    x = mod(num, 10);\n",
    "    if x == 0,\n",
    "      x = 3;\n",
    "    endif;  \n",
    "    \n",
    "    if mod(counter, 2) == 1,\n",
    "      x = -x;\n",
    "    endif;  \n",
    "    \n",
    "    pol = [pol; x];\n",
    "    num = idivide(num, 10);\n",
    "    counter = counter + 1;\n",
    "  endwhile\n",
    "  \n",
    "  % Flip around the polynomial co-efficients\n",
    "  pol = transpose(flip(pol));\n",
    "  displayPolynomial(pol);\n",
    "end\n",
    "\n",
    "function [] = displayPolynomial(pol)\n",
    "    % Function to display the formed polynomial\n",
    "    polynomial_terms = [\"x^3\"; \"x^2y\"; \"xy^2 \"; \"y^3\"; \"x^2\"; \"xy\"; \"y^2\"; \"x\"; \"y\"; \" \"];\n",
    "    poly_str = [\"\"];\n",
    "    \n",
    "    for i=1:length(pol),\n",
    "      if mod(i,2) == 0,\n",
    "        poly_str = [poly_str num2str(pol(i)) polynomial_terms(i, :)];\n",
    "      else\n",
    "        poly_str = [poly_str \" +\" num2str(pol(i)) polynomial_terms(i, :)];\n",
    "      endif\n",
    "    endfor\n",
    "    \n",
    "    printf(\"Polynomial generated from the entered mobile number\\n\");\n",
    "    disp(poly_str);\n",
    "    \n",
    "endfunction\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_polynomial() -> List:\n",
    "    \"\"\"Prompts the user for input and generates a polynomial based on the mobile number generated by the user. \n",
    "    Assumption: Mobile numbers can only be 10 digits long \n",
    "\n",
    "    Returns:\n",
    "        List: Co-efficient list for the polynomial\n",
    "    \"\"\"\n",
    "    number = input(\"Enter your cell number:\\n\")\n",
    "\n",
    "    # Validate the entered input\n",
    "    try:\n",
    "        _ = int(number.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Incorrect input format. Please enter a number!\")\n",
    "        return []\n",
    "\n",
    "    if len(number.strip()) != 10:\n",
    "        print(\"Please enter a valid number. Mobile number must be 10 digits long!\")  \n",
    "        return []\n",
    "    \n",
    "    polynomial_coefs = []\n",
    "    for idx, chr in enumerate(number):\n",
    "        coef = int(chr)\n",
    "        # In case there's a zero in the mobile number replace it with a 3\n",
    "        if coef == 0: coef = 3\n",
    "        # Alternate + and - in coefficients\n",
    "        if idx % 2 == 1:\n",
    "            coef = -1 * coef\n",
    "        polynomial_coefs.append(coef)\n",
    "    \n",
    "    return polynomial_coefs\n",
    "\n",
    "def display_polynomial(coefs: List):\n",
    "    \"\"\"[Given a list of co-efficients, displays a polynomial]\n",
    "\n",
    "    Args:\n",
    "        coefs (List): A coe-efficient polynomial\n",
    "    \"\"\"\n",
    "    terms = [\"x^3\", \"x^2y\", \"xy^2\", \"y^3\", \"x^2\", \"xy\", \"y^2\", \"x\", \"y\", \"1\"]\n",
    "    \n",
    "    polynomial = \"\"\n",
    "    for idx, (coef, term) in enumerate(zip(coefs, terms)):\n",
    "        if idx % 2 == 0:\n",
    "            polynomial += f\"+{coef}{term}\"\n",
    "        else:\n",
    "            polynomial += f\"{coef}{term}\"\n",
    "    polynomial = polynomial[:-1]\n",
    "    \n",
    "    # Print if there is a polynomial generated for reporting\n",
    "    if polynomial:\n",
    "        print(f\"\\nPolynomial corresponding to your phone number\\n{polynomial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your cell number:\n",
      " adaw123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect input format. Please enter a number!\n"
     ]
    }
   ],
   "source": [
    "# Generate a polynomial with invalid input\n",
    "poly = generate_polynomial()\n",
    "display_polynomial(poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your cell number:\n",
      " 77358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a valid number. Mobile number must be 10 digits long!\n"
     ]
    }
   ],
   "source": [
    "# Generate a polynomial with fewer/more than 10 digits\n",
    "poly = generate_polynomial()\n",
    "display_polynomial(poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your cell number:\n",
      " 7738368566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynomial corresponding to your phone number\n",
      "+7x^3-7x^2y+3xy^2-8y^3+3x^2-6xy+8y^2-5x+6y-6\n"
     ]
    }
   ],
   "source": [
    "# Generate a plynomial with valid input\n",
    "poly = generate_polynomial()\n",
    "display_polynomial(poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii** Write a code to find all critical points of $g(x, y)$. You may use built in functions like `solve` (or other similar functions) in Octave/Matlab to find the critical points. \n",
    "\n",
    "> **Deliverable(s) : The code that finds the critical points along with the display of all the calculated critical points. (1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](32_critical_points.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```octave\n",
    "## Author: vinayak <vinayak@vinayak-EXIGO-V2>\n",
    "## Created: 2022-02-23\n",
    "% Script to find out the critical points of a polynomial\n",
    "\n",
    "function [critical_points] = qn32(pol)\n",
    "  \n",
    "  % Display the polynomial created from the given cell number\n",
    "  disp(\"Polynomial co-efficients entered is as follows\");\n",
    "  disp(pol);\n",
    "  \n",
    "  % Create a container to hold the solution values\n",
    "  critical_points = [];\n",
    "  \n",
    "  % Find out the critical points using fsolve\n",
    "  % Start at different points in the function domain using random\n",
    "  % Variables and then find the roots of grad(pol) = 0\n",
    " \n",
    "  for i = 1:1000,\n",
    "    % Define the start point\n",
    "    startPoint = 1000 * randn(2, 1);\n",
    "    % Create a wrapper function for the objective/optimization function\n",
    "    optimFunc = @(pol) @(startPoint) optimizationFunction(startPoint, pol);\n",
    "    % Define the solver options\n",
    "    options = optimset (\"TolFun\", 1e-6, \"MaxIter\", 5000);\n",
    "    % Find solutions to the above objective function\n",
    "    [sol, fval, info] = fsolve(optimFunc(pol), startPoint, options);\n",
    "    % If the solution converged in this iteration, save the \n",
    "    % Point as a critical point in the matrix\n",
    "    if info == 1,\n",
    "      critical_points = addToSolution(critical_points, sol);\n",
    "    endif;\n",
    "  endfor\n",
    "  \n",
    "endfunction\n",
    "\n",
    "function [distance] = euclideanDistance(v1, v2)\n",
    "  % Given two vectors v1 and v2, compute the Euclidean distance between them\n",
    "  distance = sqrt(sum((v1 - v2).^2));\n",
    "endfunction\n",
    "\n",
    "function [sol] = addToSolution(solutionSet, newSolution)\n",
    "  % Given a set of critical points and a new critical point\n",
    "  % Check if the new point is already present in the given set\n",
    "  % If no, add it to the solution set, else return the set as is\n",
    "  n = size(solutionSet)(2);\n",
    "  present = 0;\n",
    "  for i = 1:n,\n",
    "    r = euclideanDistance(solutionSet(:, i), newSolution);\n",
    "    if r < 1e-6,\n",
    "      present = 1;\n",
    "      break;\n",
    "    endif  \n",
    "  endfor  \n",
    "  \n",
    "  % If the solution doesn't exist in the current set, add it to\n",
    "  % The current set, otherwise, just return old solution set as is\n",
    "  if present == 0,\n",
    "    sol = [solutionSet, newSolution];\n",
    "  else\n",
    "    sol = solutionSet;\n",
    "  endif;  \n",
    "  \n",
    "endfunction  \n",
    "\n",
    "function [out] = optimizationFunction(startPoint, g)\n",
    "  % Start with the x and y values at this given step\n",
    "  x = startPoint(1);\n",
    "  y = startPoint(2);\n",
    "  \n",
    "  % Solve for delg/delx = 0; delg/dely = 0 simultaneously\n",
    "  gx = 3*g(1)*x^2 + 2*g(2)*x*y + g(3)*y^2 + 2*g(5)*x + g(6)*y + g(8);  \n",
    "  gy = g(2)*x^2 + 2*g(3)*x*y + 3*g(4)*y^2 + g(6)*x + 2*g(7)*y + g(9);\n",
    "  out = [gx gy];\n",
    "endfunction\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "from typing import List, Tuple\n",
    "\n",
    "import warnings, random\n",
    "warnings.filterwarnings(\"error\")\n",
    "\n",
    "def func_val(x, y):\n",
    "    return (g[0])*(x**3) + (g[1])*(x*y) + (g[2])*(y**2) + (2*g[4])*(x) + (g[5])*(y) + (g[7])\n",
    "\n",
    "def find_critical_points(polynomial: List) -> List:\n",
    "    \"\"\"[Accepts a polynomial of 3rd degree in x and y and finds out the critical points of the same in an iterative manner]\n",
    "\n",
    "    Args:\n",
    "        polynomial (List): Co-efs of 3rd degree polynomial as a list\n",
    "\n",
    "    Returns:\n",
    "        List: A dataframe of solutions\n",
    "    \"\"\"\n",
    "    g = polynomial\n",
    "    \n",
    "    # Define the system of simultaneous equations for scipy to solve\n",
    "    def equations(p):\n",
    "        x, y = p\n",
    "\n",
    "        gx = (3*g[0])*(x**2) + (2*g[1])*(x*y) + (g[2])*(y**2) + (2*g[4])*(x) + (g[5])*(y) + (g[7])\n",
    "        gy = (g[1])*(x**2) + (2*g[2])*(x*y) + (3*g[3])*(y**2) + (g[5])*(x) + (g[6])*(y) + (g[8])\n",
    "\n",
    "        return (gx, gy)\n",
    "\n",
    "    solutions = []\n",
    "    counter = 0\n",
    "\n",
    "    # Select a random starting point in the R2 landscape and iterate for 1000 \n",
    "    # times in this landscape to find roots of the equation\n",
    "    while counter < 1000:\n",
    "        initial_x, initial_y = random.randint(-10000, 10000), random.randint(-10000, 10000)\n",
    "        try:\n",
    "            # Try to solve the equations\n",
    "            x, y =  fsolve(equations, (initial_x, initial_y))\n",
    "            counter += 1\n",
    "\n",
    "            # Rounding in order to avoid solutions which differ by a very thin margin\n",
    "            # i.e. in the 8th or 9th decimal place\n",
    "            sol = (round(x,7),round(y,7))\n",
    "            \n",
    "            # If the solution has not been encountered, then add it to the set of\n",
    "            # solutions container defined above\n",
    "            if not (sol in solutions):\n",
    "                solutions.append(sol)\n",
    "                \n",
    "        except RuntimeWarning:\n",
    "            # This is to suppress the solutions which do not converge and simply \n",
    "            # raise a warning that the solution didn't converge\n",
    "            pass\n",
    "    \n",
    "    return solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your cell number:\n",
      " 7738368566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynomial corresponding to your phone number\n",
      "+7x^3-7x^2y+3xy^2-8y^3+3x^2-6xy+8y^2-5x+6y-6\n",
      "CP 0: (x =-0.53201, y = 0.65738)\n",
      "CP 1: (x = 0.59938, y = 0.47341)\n",
      "CP 2: (x =-0.70123, y =-0.45777)\n",
      "CP 3: (x = 0.21693, y =-0.27483)\n"
     ]
    }
   ],
   "source": [
    "# Find the critical points of a random polynomial\n",
    "g = generate_polynomial()\n",
    "solutions = find_critical_points(g)\n",
    "\n",
    "# Show the critical points\n",
    "display_polynomial(g)\n",
    "for idx, point in enumerate(solutions):\n",
    "    print(f\"CP{idx:2d}: (x ={point[0]: .5f}, y ={point[1]: .5f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**iii** Write a code to determine whether they correspond to a maximum, minimum or a saddle point.\n",
    "\n",
    "\n",
    "> **Deliverable(s) : The code that identifies the type of critical points. The critical points and their type must be presented in the form of the table\n",
    "generated by code for the above polynomial.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](33_hessian.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```octave\n",
    "## Author: vinayak <vinayak@vinayak-EXIGO-V2>\n",
    "## Created: 2022-02-23\n",
    "% Script to find out the nature of critical points of a polynomial function in 2 variables\n",
    "\n",
    "function [] = qn33 (pol)\n",
    "  \n",
    "  % Call the routine to take input and find the critical points of a function\n",
    "  [cp] = qn32(pol);\n",
    "  \n",
    "  % Iterate over the individual points, find out their nature and tabulate them\n",
    "  % Find out the number of critical points obtained\n",
    "  n = size(cp)(2);\n",
    "  \n",
    "  for i = 1:n,\n",
    "    [evals, nature] = hessian(pol, cp(:, i));\n",
    "    printf(\"\\nCritical Point\\n\");%, num2str(i));\n",
    "    disp(transpose(cp(:, i)));\n",
    "    printf(\"\\nEigen Values of Hessian for this critical point as follows\\n\");\n",
    "    disp(evals);\n",
    "    printf(\"\\nNature of the critical point: \");\n",
    "    disp(nature);\n",
    "  endfor\n",
    "  \n",
    "endfunction\n",
    "\n",
    "function [evals, nature] = hessian(g, cp)\n",
    "  % Given a polynomial and it's critical point, computes the\n",
    "  % hessian matrix and it's eigen values at this point\n",
    "  x = cp(1, 1); y = cp(2, 1);\n",
    "  \n",
    "  % Define the second order partial derivative hessian matrix\n",
    "  h11 = 6*g(1)*x + 2*g(2)*y + 2*g(5);\n",
    "  h12 = 2*g(2)*x + 2*g(3)*y + g(6);\n",
    "  h21 = h12;\n",
    "  h22 = 2*g(3)*x + 6*g(4)*y + 2*g(7);  \n",
    "  hessian = [h11 h12; h21 h22];\n",
    "  \n",
    "  % Find the eigen vector/eigen value pairs for the hessian matrix\n",
    "  [_, evs] = eigs(hessian);\n",
    "  \n",
    "  % Find out the nature of evs\n",
    "  sgn = 1;\n",
    "  evals = [];\n",
    "  for i = 1:length(evs),\n",
    "    sgn = sign(evs(i,i)) * sgn;\n",
    "    evals = [evals evs(i, i)];\n",
    "  endfor  \n",
    "  \n",
    "  % If all eigen values of hessian > 0 ===> Minima\n",
    "  % If all eigen values of hessian < 0 ===> Maxima\n",
    "  % If both +ve & -ve eigen values     ===> Saddle\n",
    "  if sgn == -1,\n",
    "    nature = \"saddle\";\n",
    "  elseif (sgn == 1) && (evs(1,1) > 0),\n",
    "    nature = \"minima\";\n",
    "  elseif (sgn == 1) && (evs(1,1) < 0),\n",
    "    nature = \"maxima\";\n",
    "  endif  \n",
    "endfunction\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def determine_nature(polynomial: List, critical_point: Tuple, threshold: float = 1e-6) -> str:\n",
    "    \"\"\"[Given a polynomial and an identified critical point for the polynomial,\n",
    "    computes if the point is a maxima, minima or saddle point]\n",
    "\n",
    "    Args:\n",
    "        polynomial (List): Co-efficients of the polynomial\n",
    "        critical_point (Tuple): A critical point in R2\n",
    "        threshold (float, default: 1e-6): A zero threshold (i.e. whether the eigen value found is zero or not) \n",
    "\n",
    "    Returns:\n",
    "        str: Type of the point\n",
    "    \"\"\"\n",
    "    g = polynomial\n",
    "    cx, cy = critical_point\n",
    "\n",
    "    # Compute hessian matrix values\n",
    "    h11 = 6*g[0]*cx + 2*g[1]*cy + 2*g[4]\n",
    "    h12 = 2*g[1]*cx + 2*g[2]*cy + g[5]\n",
    "    h21 = h12\n",
    "    h22 = 2*g[2]*cx + 6*g[3]*cy + 2*g[6]\n",
    "\n",
    "    # Find the determinant of this hessian matrix\n",
    "    D = h11 * h22 - h12 * h21\n",
    "       \n",
    "    # Check the signs of eigen values\n",
    "    if abs(D) < threshold:\n",
    "        return \"inconclusive\"\n",
    "    elif D < 0:\n",
    "        return \"saddle\"\n",
    "    elif ((D > 0) and (h11 > 0)):\n",
    "        return \"minima\"\n",
    "    elif ((D > 0) and (h11 < 0)):\n",
    "        return \"maxima\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your cell number:\n",
      " 7738368566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynomial corresponding to your phone number\n",
      "+7x^3-7x^2y+3xy^2-8y^3+3x^2-6xy+8y^2-5x+6y-6\n",
      "\n",
      "CP 0: (x =-0.70123, y =-0.45777) | Nature: saddle\n",
      "CP 1: (x = 0.21693, y =-0.27483) | Nature: minima\n",
      "CP 2: (x = 0.59938, y = 0.47341) | Nature: saddle\n",
      "CP 3: (x =-0.53201, y = 0.65738) | Nature: maxima\n"
     ]
    }
   ],
   "source": [
    "# Find the critical points of a random polynomial\n",
    "g = generate_polynomial()\n",
    "solutions = find_critical_points(g)\n",
    "\n",
    "# Show the Polynomial\n",
    "display_polynomial(g)\n",
    "print()\n",
    "\n",
    "# Determine the nature of the critical points and print the same\n",
    "for idx, point in enumerate(solutions):\n",
    "    nature = determine_nature(g, point)\n",
    "    print(f\"CP{idx:2d}: (x ={point[0]: .5f}, y ={point[1]: .5f}) | Nature: {nature}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
