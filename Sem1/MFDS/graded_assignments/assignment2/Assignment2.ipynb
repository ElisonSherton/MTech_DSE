{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DSECL ZC416 - Mathematical Foundations for Data Science**\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Use Python for Q1 and Q2. We recommend Octave for Q3 due to availability of built in function ’solve’.\n",
    "\n",
    "2. Attach only the relevant data in your submission as per the deliverables mentioned.\n",
    "\n",
    "3. By random entries, we mean a system generated random number. No marks would be awarded for deterministic entries.\n",
    "\n",
    "4. This is not a group activity. Each student should do the problems and submit individually.\n",
    "\n",
    "5. Submissions beyond 3rd of March, 2022, 17.00 hrs would not be graded\n",
    "\n",
    "6. Assignments sent via email would not be accepted\n",
    "\n",
    "7. Copying is strictly prohibited. Adoption of unfair means would lead to disciplinary action.\n",
    "\n",
    "8. Assignment have to be scanned as a pdf document and uploaded on canvas. File name should be your bitsid.pdf\n",
    "\n",
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Question: Gram-Schmidt Algorithm & QR Decomposition\n",
    "\n",
    "**i.** Write a code to generate a random matrix A of size $m × n$ with $m > n$ and calculate its Frobenius norm, $|| \\cdot ||_F$. The entries of A must be of the form r.dddd (example 5.4316). The inputs are the positive integers m and n and the output should display the the dimensions and the calculated norm value.\n",
    "\n",
    "\n",
    "\n",
    "> **Deliverable(s) : The code with the desired input and output (0.5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from typing import List, Tuple\n",
    "import random, copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A function to generate a random entry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_entry() -> float:\n",
    "    \"\"\"[Returns a random number of the form r.dddd]\n",
    "\n",
    "    Returns:\n",
    "        float: A random number\n",
    "    \"\"\"\n",
    "\n",
    "    digits = \"\"\n",
    "    for i in range(5):\n",
    "        dig = random.randint(0, 9)\n",
    "        if i == 4: dig = random.randint(1, 9)\n",
    "        digits = digits + str(dig)\n",
    "        if i == 0: digits += \".\"\n",
    "    return float(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "**Create a random matrix of m x n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_matrix(m:int, n:int, wide:bool = False) -> List:\n",
    "    \"\"\"[Takes in the number of rows and columns and generates a matrix of size m x n. \n",
    "    Check if we need to create a random wide matrix or not, if yes, then validate, else, just generate]\n",
    "\n",
    "    Args:\n",
    "        m (int): Number of rows of the matrix\n",
    "        n (int): Number of columns of the matrix\n",
    "        wide (bool, default = False): Whether wider or square matrix are allowed\n",
    "\n",
    "    Returns:\n",
    "        List: A matrix as a list of lists\n",
    "    \"\"\"\n",
    "    if not wide:\n",
    "        if m <= n:\n",
    "            print(\"Error: Requested matrix is square or wide; It must be tall. Please give m > n\")\n",
    "            return []\n",
    "    \n",
    "    A = []\n",
    "    for i in range(m):\n",
    "        ith_row = []\n",
    "        for j in range(n):\n",
    "            ith_row.append(generate_random_entry())\n",
    "        A.append(ith_row)\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "**Compute the frobenius norm of a matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frob_norm(A: List) -> Tuple:\n",
    "    \"\"\"[Takes in a matrix A and computes the frobenius norm of that matrix]\n",
    "\n",
    "    Args:\n",
    "        A (List): A matrix represented as List of Lists\n",
    "\n",
    "    Returns:\n",
    "        Tuple: [The frobenius norm of the matrix, and the number of additions, multiplications, divisions needed to compute the norm of the matrix]\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(A) == 0:\n",
    "        print(\"Empty matrix passed. Pass a finite matrix\")\n",
    "        return -1.0\n",
    "    if len(A[0]) == 0:\n",
    "        print(\"Empty matrix passed. Pass a finite matrix\")\n",
    "        return -1.0\n",
    "    \n",
    "    additions, multiplications, divisions, root = -1, 0, 0, 0\n",
    "    fro_norm = 0.0\n",
    "\n",
    "    for row in A:\n",
    "        for element in row:\n",
    "            fro_norm += element * element\n",
    "            additions += 1\n",
    "            multiplications += 1\n",
    "    \n",
    "    fro_norm = (fro_norm) ** 0.5\n",
    "    root += 1\n",
    "    return (fro_norm, (additions, multiplications, divisions, root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "**Convenience function to display a matrix A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_matrix(A):\n",
    "    \"\"\"\n",
    "    Convenience function to display a matrix in pretty formatting\n",
    "    \"\"\"\n",
    "    nr = len(A)\n",
    "    nc = len(A[0])\n",
    "    matrix_string = \"        \"\n",
    "    for col in range(nc):\n",
    "        matrix_string += f\"C{col+1:<7}\"\n",
    "    matrix_string += \"\\nR1   \"\n",
    "    for idx, r in enumerate(A):\n",
    "        for element in r:\n",
    "            matrix_string += f\"{element: .4f} \"\n",
    "        if idx < nr - 1:\n",
    "            matrix_string += f\"\\nR{idx + 2:<3} \"\n",
    "    print(matrix_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Requested matrix is square or wide; It must be tall. Please give m > n\n"
     ]
    }
   ],
   "source": [
    "# Try generating a random wide matrix\n",
    "# Expected Output: Error!\n",
    "A = create_random_matrix(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1      C2      C3      C4      \n",
      "R1    5.2591  8.6375  1.6204  8.9743 \n",
      "R2    2.2497  7.3639  5.3717  2.4046 \n",
      "R3    4.6519  7.2813  0.3548  1.2868 \n",
      "R4    3.7245  7.7674  0.4333  5.3857 \n",
      "R5    1.0285  8.4922  9.7607  7.0608 \n"
     ]
    }
   ],
   "source": [
    "# Try generating a tall matrix\n",
    "# Expected Output: A tall matrix\n",
    "A = create_random_matrix(5, 4)\n",
    "display_matrix(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius Norm of matrix A: 26.02868\n"
     ]
    }
   ],
   "source": [
    "# Try caluclating frobenius norm of generated matrix\n",
    "# Expected Output: A float\n",
    "n, _ = frob_norm(A)\n",
    "print(f\"Frobenius Norm of matrix A: {n:0.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "**ii** Write a code to decide if Gram-Schmidt Algorithm can be applied to columns of a given matrix A through calculation of rank. The code should print appropriate messages indicating whether Gram-Schmidt is applicable on columns of the matrix or not.\n",
    "\n",
    "> **Deliverable(s) : The code that performs the test. (1)**\n",
    "\n",
    "**Methodology**\n",
    "\n",
    "- Find the row reduced echelon form of the given matrix\n",
    "\n",
    "- If rank of the matrix = number of columns of A $\\Rightarrow$ A has LI columns $\\Rightarrow$ A can be decomposed into $QR$ form\n",
    "\n",
    "- If rank of matrix is less than number of columns of A, A has Linearly Dependent columns $\\Rightarrow$ A cannot be expressed as $QR$\n",
    "\n",
    "**PS**\n",
    "\n",
    "- To check if an element is zero in REF, we use a very small threshold value of 1e-6. Since computationally, we can get numbers very close to zero but not actually zero while performing row reduction; we are bound to take some small threshold value for near zero quantities.\n",
    "\n",
    "*Define some functions to perform elementary matrix operations i.e. inner product, vector addition and scalar multiplication, matrix multiplication, matrix transpose and eventually column normed matrix. These functions will also help us in later computations throughout the assignment*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "**Function to compute the inner product of two vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product(v1:List, v2:List) -> Tuple:\n",
    "    \"\"\"Given two vectors v1 and v2, computes their inner product\n",
    "\n",
    "    Args:\n",
    "        v1 (List): [A vector represented as a list]\n",
    "        v2 (List): [A vector represented as a list]\n",
    "\n",
    "    Returns:\n",
    "        Tuple: [A tuple of the inner product & number of additions, multiplications and divisions needed for performing the inner product]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Here initialize addition to -1 because to compute the inner product of two \n",
    "    # n dimensional vectors we only need n - 1 additions and n multiplications\n",
    "    additions, multiplications, divisions = -1, 0, 0\n",
    "    \n",
    "    dot_product = 0.0\n",
    "    for e1, e2 in zip(v1, v2):\n",
    "        dot_product += e1 * e2\n",
    "        additions += 1; multiplications += 1\n",
    "    \n",
    "    return (dot_product, (additions, multiplications, divisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "**Function to compute vector addition of two vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_addition(v1:List, v2:List) -> Tuple:\n",
    "    \"\"\"[Given two vectors, adds them and computes the number of +, -, / needed for the same]\n",
    "\n",
    "    Args:\n",
    "        v1 (List): [A vector represented as a list]\n",
    "        v2 (List): [A vector represented as a list]\n",
    "\n",
    "    Returns:\n",
    "        Tuple: [A tuple representing vector subtraction result and the number of +, -, / needed to compute the result]\n",
    "    \"\"\"\n",
    "    \n",
    "    additions, multiplications, divisions = 0, 0, 0\n",
    "    resultant = []\n",
    "    \n",
    "    for e1, e2 in zip(v1, v2):\n",
    "        resultant.append(e1 + e2)\n",
    "        additions += 1\n",
    "    \n",
    "    return (resultant, (additions, multiplications, divisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "**Function to compute scalar multiplication of a scalar with a vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_multiplication(v1:List, k: float) -> Tuple:\n",
    "    \"\"\"[Given a vector and a scalar, scales the vector appropriately]\n",
    "\n",
    "    Args:\n",
    "        v1 (List): [A vector represented as a list]\n",
    "        k (float): [A scalar]\n",
    "\n",
    "    Returns:\n",
    "        Tuple: [A tuple representing scalar multiplication result and the number of +, -, / needed to compute the result]\n",
    "    \"\"\"\n",
    "    \n",
    "    additions, multiplications, divisions = 0, 0, 0\n",
    "    resultant = []\n",
    "    \n",
    "    for e1 in v1:\n",
    "        resultant.append(k * e1)\n",
    "        multiplications += 1\n",
    "    \n",
    "    return (resultant, (additions, multiplications, divisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "**Function to perform matrix multiplication of two matrices A & B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_multiplication(A:List, B:List) -> Tuple:\n",
    "    \"\"\"[Given two matrices as list of lists, computes their matrix product]\n",
    "\n",
    "    Args:\n",
    "        A (List): [A matrix of dimension m x n]\n",
    "        B (List): [A matrix of dimension n x m]\n",
    "\n",
    "    Returns:\n",
    "        List: [A tuple of Matrix product as a list of lists and the number of additions, multiplications and divisions needed for performing the operation]\n",
    "    \"\"\"\n",
    "\n",
    "    a, m, d = 0, 0, 0\n",
    "\n",
    "    nrA, ncA = len(A), len(A[0])\n",
    "    nrB, ncB = len(B), len(B[0])\n",
    "\n",
    "    if ncA != nrB:\n",
    "        print(\"Matrix dimension mismatch, please input valid matrices\")\n",
    "        return ([], (a, m, d))\n",
    "    \n",
    "    B_columns = []\n",
    "    # Get a list of the columns of B\n",
    "    for c in range(ncB):\n",
    "        col = []\n",
    "        for r in range(nrB):\n",
    "            col.append(B[r][c])\n",
    "        B_columns.append(col)\n",
    "    \n",
    "    resultant_matrix = []\n",
    "    \n",
    "    # Iteratively multiply rows of A and columns of B in order to \n",
    "    # Compute the product A matmul B\n",
    "    for row in A:\n",
    "        resultant_row = []\n",
    "        for column in B_columns:\n",
    "            abij, (add, mult, div) = inner_product(row, column)\n",
    "            a += add; m += mult; d += div\n",
    "            resultant_row.append(abij)\n",
    "        resultant_matrix.append(resultant_row)\n",
    "    \n",
    "    return (resultant_matrix, (a, m, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "**Function to compute the transpose of a matrix A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_transpose(A:List) -> List:\n",
    "    \"\"\"[Given a matrix A, generate it's transpose]\n",
    "\n",
    "    Args:\n",
    "        A (List): [A matrix represented as list of lists]\n",
    "\n",
    "    Returns:\n",
    "        List: [Transpose of the matrix represented as list of lists]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the rows and columns of A\n",
    "    nr, nc = len(A), len(A[0])\n",
    "    \n",
    "    # Create a container for A_transpose\n",
    "    A_transpose = []\n",
    "\n",
    "    # Compute the transpose of A\n",
    "    for c in range(nc):\n",
    "        col = []\n",
    "        for r in range(nr):\n",
    "            col.append(A[r][c])\n",
    "        A_transpose.append(col)\n",
    "    \n",
    "    return A_transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "**Function to compute the column normalized version of a matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(A: List) -> Tuple:\n",
    "    \"\"\"[Given a matrix A, normalizes it's columns using l2-norm and returns the normalized matrix as a List of lists and also the number of +, -, /, sqrt needed for computing the result]\n",
    "    Args:\n",
    "        A (List): [Matrix represented as list of lists]\n",
    "    Returns:\n",
    "        Tuple: [A tuple of the normalized matrix and the count of +,-,/ needed for generating the matrix]\n",
    "    \"\"\"\n",
    "    # Initialize the number of additions, multiplications, divisions to zero\n",
    "    a, m, d, root = 0, 0, 0, 0\n",
    "\n",
    "    # If given matrix is a null matrix, return a null matrix\n",
    "    if len(A) == 0:\n",
    "        return ([], (a, m, d))\n",
    "    if len(A[0]) == 0:\n",
    "        return ([[]], (a, m, d))\n",
    "    \n",
    "    # Find the number of rows and columns of matrix A\n",
    "    nr, nc = len(A), len(A[0])\n",
    "    # First get the columns of A \n",
    "    A_columns = matrix_transpose(A)\n",
    "    # Compute the normed column matrix now\n",
    "    normalizedA = []\n",
    "\n",
    "    for col in A_columns:\n",
    "        dot_product, (add, mult, div) = inner_product(col, col)\n",
    "        a += add; m+= mult; d += div\n",
    "        \n",
    "        l2norm = (dot_product) ** 0.5\n",
    "        root += 1\n",
    "    \n",
    "        scaled_vector, (add, mult, div) = scalar_multiplication(col, 1 / l2norm)\n",
    "        # Since I have considered division ads multiplication with reciprocal here, I am adding the scaling multiplications to division count here\n",
    "        d += mult        \n",
    "        normalizedA.append(scaled_vector)\n",
    "        \n",
    "    # Get the matrix A in row major order again\n",
    "    normedARowMajor = matrix_transpose(normalizedA)   \n",
    "    return (normedARowMajor, (a, m, d, root))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "**Functions to move from flat nd vectors to a tall matrix of width 1 and vice versa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_column_matrix(m: List) -> List:\n",
    "    \"\"\"[Flatten a column matrix of n x 1 into an n-dimensional vector]\n",
    "\n",
    "    Args:\n",
    "        m (List): [A tall matrix of width 1]\n",
    "\n",
    "    Returns:\n",
    "        List: [A flattened vector]\n",
    "    \"\"\"\n",
    "    return [x[0] for x in m]\n",
    "\n",
    "def expand_column_vector(m: List) -> List:\n",
    "    \"\"\"[Convert a flat n-dimensional column vector into an n x 1 matrix]\n",
    "\n",
    "    Args:\n",
    "        m (List): [A flat nd vector]\n",
    "\n",
    "    Returns:\n",
    "        List: [A tall width=1 matrix]\n",
    "    \"\"\"\n",
    "    return [[x] for x in m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "**Now we will start with the real qn 1.ii by taking help of the functions defined above. Define a function to compute the row reduced echelon form of a matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rreduce(A:List, threshold:float = 1e-6) -> Tuple:\n",
    "    \"\"\"[Given a matrix A as a list of lists, compute it's row reduced echelon form.\n",
    "    Return that along with the rank of the matrix]\n",
    "\n",
    "    Args:\n",
    "        A (List): A m x n tall matrix\n",
    "        threshold (float, optional): When comparing the pivot elements, what magnitude of a value counts as zero magnitufe. Defaults to 1e-6.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: A tuple of row reduced echelon form and the decision i.e. whether\n",
    "        the matrix has linearly independent columns or not\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the number of additions, multiplications divisions to null\n",
    "    a, m, d = 0, 0, 0\n",
    "    \n",
    "    # Create a copy of the original matrix otherwise original\n",
    "    # matrix will get overwritten\n",
    "    A = copy.deepcopy(A)\n",
    "    \n",
    "    # Check if the matrix is empty\n",
    "    if len(A) == 0:\n",
    "        return ([], False)\n",
    "    if len(A[0]) == 0:\n",
    "        return ([[]], False)\n",
    "    \n",
    "    # Find out number of rows and columns\n",
    "    nr, nc = len(A), len(A[0])            \n",
    "    \n",
    "    # Get Echelon form using row reduction operations\n",
    "    # Only iterate for as many times as number of columns since \n",
    "    # tall matrix can't have more pivot elements than number of columns\n",
    "    for i in range(nc - 1):\n",
    "        \n",
    "        pivot_element = A[i][i]\n",
    "        \n",
    "        # Make all the elements below the pivot to be zero\n",
    "        # in an iterative manner\n",
    "        for j in range(i + 1, nr):\n",
    "                        \n",
    "            # Find the pivot element and compute the scaling factor\n",
    "            div_factor = A[j][i] / pivot_element     \n",
    "            d += 1\n",
    "            \n",
    "            # Scale the ith row based on the above factor\n",
    "            scaled_vector, (add, mult, div) = scalar_multiplication(A[i], -1 * div_factor)\n",
    "            a += add; m += mult; d += div;\n",
    "            \n",
    "            # Subtract the scaled row from A[j]\n",
    "            transformed_row, (add, mult, div) = vector_addition(A[j], scaled_vector)\n",
    "            \n",
    "            # Deduct the counts of add and mult by (i + 1) because when \n",
    "            # doing row reduction we are computing pivots in such a way \n",
    "            # that the elements below the pivot should become zeros \n",
    "            # and the elements to the left of the pivot are already zeros\n",
    "            # so no need to compute that term again and add it\n",
    "            add -= (i + 1); mult -= (i + 1);\n",
    "            a += add; m += mult; d += div;\n",
    "            \n",
    "            A[j] = transformed_row\n",
    "    \n",
    "    # Check the leading diagonal entries; I a few of them are zeros \n",
    "    # or near zeros, then given matrix has rank lower than nc(A)\n",
    "    col_rank = True\n",
    "    for i in range(nc):\n",
    "        if abs(A[i][i]) <= threshold:\n",
    "            col_rank = False\n",
    "            break\n",
    "                    \n",
    "    return (A, col_rank, (a, m, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1      C2      C3      C4      \n",
      "R1    3.5691  6.3711  4.3996  8.5423 \n",
      "R2    0.7185  0.5797  7.8228  9.8358 \n",
      "R3    9.1817  8.8191  6.2966  9.5167 \n",
      "R4    9.0966  0.6133  0.4219  8.1412 \n",
      "R5    6.3946  8.7778  8.6234  9.0252 \n"
     ]
    }
   ],
   "source": [
    "# Create a random tall matrix\n",
    "# Expected output: A tall matrix\n",
    "A = create_random_matrix(5,4)\n",
    "display_matrix(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1      C2      C3      C4      \n",
      "R1    3.5691  6.3711  4.3996  8.5423 \n",
      "R2    0.0000 -0.7029  6.9371  8.1161 \n",
      "R3    0.0000  0.0000 -79.7436 -99.8805 \n",
      "R4    0.0000  0.0000  0.0000  12.6177 \n",
      "R5    0.0000  0.0000  0.0000 -5.0588 \n",
      "\n",
      "Adds  required 20\n",
      "Mults required 20\n",
      "Divs  required 09\n",
      "\n",
      "A has linearly independent columns. Can apply GS Algorithm.\n"
     ]
    }
   ],
   "source": [
    "# Row reduce the matrix into it's REF and see if it's columns are linearly independent\n",
    "# Expected output: REF of generated matrix, primitive operations count, whether cols are LI\n",
    "ref, dec, (a, m ,d) = rreduce(A)\n",
    "display_matrix(ref)\n",
    "print(f\"\\nAdds  required {a:02d}\\nMults required {m:02d}\\nDivs  required {d:02d}\\n\")\n",
    "if dec == True:\n",
    "    print(f\"A has linearly independent columns. Can apply GS Algorithm.\")\n",
    "else:\n",
    "    print(f\"A has linearly dependent columns. Cannot apply GS Algorithm.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purposely generate a matrix where rows are linearly dependent\n",
    "# And check if the GS Algorithm can be applied to this matrix\n",
    "# Expected output: r < nc => Cannot apply GS Algorithm\n",
    "r1 = [generate_random_entry() for i in range(3)]\n",
    "r2 = [generate_random_entry() for i in range(3)]\n",
    "r3 = [0.1*(x + y) for x, y  in zip(r1, r2)]\n",
    "r4 = [(x - y)/2 for x, y in zip(r2, r3)]\n",
    "A = [r1,r2,r3,r4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1      C2      C3      \n",
      "R1    3.4374  8.5595  2.0455 \n",
      "R2    4.9174  1.3463  4.7817 \n",
      "R3    0.8355  0.9906  0.6827 \n",
      "R4    2.0410  0.1779  2.0495 \n"
     ]
    }
   ],
   "source": [
    "display_matrix(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1      C2      C3      \n",
      "R1    3.4374  8.5595  2.0455 \n",
      "R2    0.0000 -10.8986  1.8555 \n",
      "R3    0.0000  0.0000 -0.0000 \n",
      "R4    0.0000  0.0000 -0.0000 \n",
      "\n",
      "Adds  required 08\n",
      "Mults required 08\n",
      "Divs  required 05\n",
      "\n",
      "A has linearly dependent columns. Cannot apply GS Algorithm.\n"
     ]
    }
   ],
   "source": [
    "# Row reduce the matrix into it's REF and see if it's \n",
    "# columns are linearly independent\n",
    "# Expected output: REF of generated matrix, primitive\n",
    "# operations count, whether cols are LI\n",
    "ref, dec, (a, m ,d) = rreduce(A)\n",
    "display_matrix(ref)\n",
    "print(f\"\\nAdds  required {a:02d}\\nMults required {m:02d}\\nDivs  required {d:02d}\\n\")\n",
    "if dec == True:\n",
    "    print(f\"A has linearly independent columns. Can apply GS Algorithm.\")\n",
    "else:\n",
    "    print(f\"A has linearly dependent columns. Cannot apply GS Algorithm.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "**iii**: Write a code to generate the orthogonal matrix Q from a matrix A by performing the Gram-Schmidt orthogonalization method. Ensure that A has linearly independent columns by checking the rank. Keep generating A until the linear independence is obtained.\n",
    "\n",
    "> **Deliverable(s) : The code that produces matrix Q from A (1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_schmidt_orthogonalization(A: List) -> Tuple:\n",
    "    \"\"\"[Given a matrix A, checks if it's columns are Linearly Independent and if yes, generates an orthogonal matrix from the same]\n",
    "\n",
    "    Args:\n",
    "        A (List): [Matrix represented as list of lists]\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (A tuple representing whether A contains linearly independent columns and if yes, an orthogonal matrix generated from A)\n",
    "    \"\"\"\n",
    "    \n",
    "    # If the vector is null then simply return\n",
    "    if len(A) == 0:\n",
    "        return (False, [])\n",
    "    if len(A[0]) == 0:\n",
    "        return (False, [[]])\n",
    "    \n",
    "    # Compute the number of rows and columns of matrix A\n",
    "    nr, nc = len(A), len(A[0])\n",
    "    A_columns = matrix_transpose(A)\n",
    "    \n",
    "    # Check if A has linearly independent columns or not\n",
    "    # If no, then cannot apply GS Algorithm\n",
    "    ref, dec, _ = rreduce(A)\n",
    "    if not dec:\n",
    "        return (False, [])\n",
    "    print(f\"\\nThe given matrix A has linearly independent columns.\\nHence we can compute Gram-Schmidt Orthogonalization\\n\\nREF of given matrix as follows\\n\") \n",
    "    display_matrix(ref)\n",
    "    \n",
    "    # Start generating an orthogonal basis for A\n",
    "    v = []\n",
    "    vi_inner_product = []\n",
    "\n",
    "    # Initialize the addition, multiplication and division counts to zeros\n",
    "    additions, multiplications, divisions = 0, 0, 0\n",
    "    \n",
    "    # Iterate over the columns of A\n",
    "    for n in range(nc):\n",
    "\n",
    "        xi = A_columns[n]\n",
    "        vi = xi\n",
    "        \n",
    "        for it in range(n):\n",
    "            \n",
    "            # Compute xi.vi inner product\n",
    "            xivi, (a, m, d) = inner_product(xi, v[it])\n",
    "            additions += a; multiplications += m; divisions += d\n",
    "            \n",
    "            # Check if vi's inner product exists\n",
    "            if it < (len(vi_inner_product)):\n",
    "                vivi = vi_inner_product[it]\n",
    "            else:\n",
    "                vivi, (a, m, d) = inner_product(v[-1], v[-1])\n",
    "                additions += a; multiplications += m; divisions += d\n",
    "                vi_inner_product.append(vivi)\n",
    "            \n",
    "            scaling_factor = -1 * xivi / vivi\n",
    "            divisions += 1\n",
    "            \n",
    "            scaled_vector, (a, m, d) = scalar_multiplication(v[it], scaling_factor)\n",
    "            additions += a; multiplications += m; divisions += d\n",
    "\n",
    "            vi, (a, m, d) = vector_addition(vi, scaled_vector)\n",
    "            additions += a; multiplications += m; divisions += d\n",
    "        \n",
    "        v.append(vi)\n",
    "    \n",
    "    # Reframe the matrix in row major order\n",
    "    O = matrix_transpose(v)\n",
    "        \n",
    "    return (O, (additions, multiplications, divisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly Generated Matrix\n",
      "        C1      C2      C3      C4      \n",
      "R1    5.6746  5.9481  9.3971  0.6883 \n",
      "R2    0.6626  9.3141  7.9155  7.0722 \n",
      "R3    7.4018  1.2719  3.0045  9.8976 \n",
      "R4    3.0017  8.5847  3.8409  6.3325 \n",
      "R5    7.5427  8.1981  5.6408  5.2072 \n",
      "\n",
      "The given matrix A has linearly independent columns.\n",
      "Hence we can compute Gram-Schmidt Orthogonalization\n",
      "\n",
      "REF of given matrix as follows\n",
      "\n",
      "        C1      C2      C3      C4      \n",
      "R1    5.6746  5.9481  9.3971  0.6883 \n",
      "R2    0.0000  8.6196  6.8182  6.9918 \n",
      "R3    0.0000  0.0000 -4.1218  14.2615 \n",
      "R4    0.0000  0.0000  0.0000 -17.2369 \n",
      "R5    0.0000  0.0000  0.0000 -20.4440 \n",
      "\n",
      "Linearly independent cols obtained from GSO procedure\n",
      "        C1      C2      C3      C4      \n",
      "R1    5.6746  0.8799  3.8353 -3.1127 \n",
      "R2    0.6626  8.7223  1.6837  3.8864 \n",
      "R3    7.4018 -5.3389 -0.0492  5.1526 \n",
      "R4    3.0017  5.9038 -2.6232  0.1533 \n",
      "R5    7.5427  1.4615 -1.9410 -3.1169 \n"
     ]
    }
   ],
   "source": [
    "# Create a random matrix A and compute normalize their cols using gram schmidt orthogonalization procedure\n",
    "# Expected output: The matrix and it's gram-schmidt orthogonalization matrix\n",
    "x = create_random_matrix(5, 4)\n",
    "print(\"Randomly Generated Matrix\")\n",
    "display_matrix(x)\n",
    "v, (a, m, d) = gram_schmidt_orthogonalization(x)\n",
    "\n",
    "if v:\n",
    "    print(f\"\\nLinearly independent cols obtained from GSO procedure\")\n",
    "    display_matrix(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "**iv**: Write a code to create a QR decomposition of the matrix A by utilizing the code developed in the previous sub-parts of this question. Find the matrices Q and R and then display the value $||A - (QR)||_F$ , where $||\\cdot||_F$ is the Frobenius norm. The code should also display the total number of additions, multiplications and divisions to find the result.\n",
    "\n",
    "> **Deliverable(s) : The code with the said input and output. The results obtained for A generated with m = 7 and n = 5 with random entries described above. (2.5)**\n",
    "\n",
    "**Methodology**\n",
    "\n",
    "Computing gram-schmidt orthogonalization requires several steps as follows\n",
    "\n",
    "- Verify A has LI columns $\\Rightarrow$ Compute the REF and ascertain $Rank = nc(A)$\n",
    "\n",
    "- If above condition is met, orthogonalize the columns of matrix A using GS algorithm\n",
    "\n",
    "- Normalize columns of the orthogonal matrix obtained above\n",
    "\n",
    "- $A = QR \\Rightarrow Q^{-1}A = Q^{-1}QR \\Rightarrow R = Q^TA \\because Q^{-1} = Q^T \\text{as Q is orthonormal}$\n",
    "\n",
    "- Compute the matrix product $Q^TA$ to find $R$.\n",
    "\n",
    "- Find out the primitive counts at each step of the procedure and report them individually and the totals as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Randomly Generated Matrix\n",
      "        C1      C2      C3      C4      C5      \n",
      "R1    8.1922  4.5633  9.7163  8.6341  4.9115 \n",
      "R2    1.7787  9.0392  8.7342  1.3394  4.6308 \n",
      "R3    5.7562  2.1918  9.3588  9.3512  5.3182 \n",
      "R4    9.6812  1.2139  4.9034  5.4118  0.2391 \n",
      "R5    9.5561  4.3749  4.8509  7.6171  4.4657 \n",
      "R6    1.9317  0.9016  6.3087  0.0823  4.3422 \n",
      "R7    2.7957  5.4556  8.0482  9.7882  1.5709 \n",
      "\n",
      "The given matrix A has linearly independent columns.\n",
      "Hence we can compute Gram-Schmidt Orthogonalization\n",
      "\n",
      "REF of given matrix as follows\n",
      "\n",
      "        C1      C2      C3      C4      C5      \n",
      "R1    8.1922  4.5633  9.7163  8.6341  4.9115 \n",
      "R2    0.0000  8.0484  6.6246 -0.5352  3.5644 \n",
      "R3    0.0000  0.0000  3.3668  3.2170  2.3165 \n",
      "R4    0.0000  0.0000  0.0000 -2.0698 -1.5544 \n",
      "R5    0.0000  0.0000  0.0000  0.0000  0.8785 \n",
      "R6    0.0000  0.0000  0.0000  0.0000  4.8601 \n",
      "R7    0.0000  0.0000  0.0000  0.0000 -7.1194 \n",
      "\n",
      "Matrix Q\n",
      "        C1      C2      C3      C4      C5      \n",
      "R1    0.4730  0.0848  0.1687  0.0032  0.0393 \n",
      "R2    0.1027  0.8386 -0.1222 -0.4120 -0.0589 \n",
      "R3    0.3323 -0.0438  0.5675  0.2637  0.2975 \n",
      "R4    0.5589 -0.3256 -0.1181 -0.2525 -0.6648 \n",
      "R5    0.5517  0.0023 -0.5111  0.0871  0.5506 \n",
      "R6    0.1115  0.0022  0.5734 -0.5211  0.1489 \n",
      "R7    0.1614  0.4262  0.1748  0.6464 -0.3730 \n",
      "\n",
      "Matrix R\n",
      "        C1      C2      C3      C4      C5      \n",
      "R1    17.3206  7.8884  16.0225  16.1455  7.9013 \n",
      "R2    0.0000  9.8132  9.5974  3.8734  4.6786 \n",
      "R3   -0.0000 -0.0000  7.8485  3.8255  3.7346 \n",
      "R4    0.0000  0.0000  0.0000  7.5231 -1.4083 \n",
      "R5   -0.0000 -0.0000 -0.0000 -0.0000  3.8629 \n",
      "\n",
      "Matrix (A - QR)\n",
      "        C1      C2      C3      C4      C5      \n",
      "R1    0.0000  0.0000  0.0000  0.0000  0.0000 \n",
      "R2    0.0000  0.0000  0.0000  0.0000  0.0000 \n",
      "R3    0.0000  0.0000  0.0000  0.0000  0.0000 \n",
      "R4    0.0000 -0.0000  0.0000 -0.0000  0.0000 \n",
      "R5    0.0000  0.0000  0.0000  0.0000  0.0000 \n",
      "R6    0.0000  0.0000  0.0000  0.0000  0.0000 \n",
      "R7   -0.0000 -0.0000 -0.0000 -0.0000  0.0000 \n",
      "\n",
      "Frobenius norm of (A - QR) = 0.00000\n",
      "\n",
      "\n",
      "Operation Counts as follows\n",
      "\n",
      "REF                           | A:50  | M:50  | D:18  | Sqrt:0  \n",
      "GS Algorithm                  | A:154 | M:168 | D:10  | Sqrt:0  \n",
      "Orthonormalization            | A:30  | M:35  | D:35  | Sqrt:5  \n",
      "R = Q'A Computation           | A:150 | M:175 | D:0   | Sqrt:0  \n",
      "(A - QR) Computation          | A:35  | M:0   | D:0   | Sqrt:0  \n",
      "Norm(A - QR) Computation      | A:34  | M:35  | D:0   | Sqrt:1  \n",
      "Total Count                   | A:453 | M:463 | D:63  | Sqrt:6  \n"
     ]
    }
   ],
   "source": [
    "# Create a random matrix\n",
    "A = create_random_matrix(7, 5)\n",
    "\n",
    "# Display the matrix generated\n",
    "print(\"\\nRandomly Generated Matrix\")\n",
    "display_matrix(A)\n",
    "\n",
    "# Compute REF of the matrix and count the number of primitive operations incurred in the same\n",
    "ref, decision, (aref, mref, dref) = rreduce(A)\n",
    "\n",
    "if decision:\n",
    "    # Apply GS Algorithm to find an orthogonal basis\n",
    "    v, (ags, mgs, dgs) = gram_schmidt_orthogonalization(A)\n",
    "\n",
    "    # Make the orthogonal basis into an orthonormal one\n",
    "    Q, (anorm, mnorm, dnorm, rootnorm) = normalize_columns(v)\n",
    "    \n",
    "    # Compute the matrix R using the orthonormal matrix and the original matrix\n",
    "    R, (aR, mR, dR) = matrix_multiplication(matrix_transpose(Q), A)\n",
    "    \n",
    "    # Compute the matrix QR\n",
    "    QR, (aQR, mQR, dQR) = matrix_multiplication(Q, R)\n",
    "    \n",
    "    # Compute the matrix A - QR\n",
    "    delta = []\n",
    "    addDelta, multDelta, divDelta = 0, 0, 0\n",
    "    for a_row, qr_row in zip(A, QR):\n",
    "        scaled_vector, _ = scalar_multiplication(qr_row, -1)\n",
    "        resultant, (a, m, d) = vector_addition(a_row, scaled_vector)\n",
    "        addDelta += a; multDelta += m; divDelta += d\n",
    "        delta.append(resultant)\n",
    "    \n",
    "    # Compute the frobenius norm of A - QR = delta\n",
    "    fn, (afro, mfro, divfro, rootfro) = frob_norm(delta)\n",
    "    \n",
    "    \n",
    "    # Display the matrices Q, R and A - QR respectively\n",
    "    print(f\"\\nMatrix Q\")\n",
    "    display_matrix(Q)\n",
    "    print(f\"\\nMatrix R\")\n",
    "    display_matrix(R)\n",
    "    print(f\"\\nMatrix (A - QR)\")\n",
    "    display_matrix(delta)\n",
    "    print(f\"\\nFrobenius norm of (A - QR) = {fn:.5f}\")\n",
    "    \n",
    "    \n",
    "    # Find out the counts for each and every step along the way\n",
    "    total_additions = aref + ags + anorm + aR + addDelta + afro \n",
    "    total_multiplications = mref + mgs + mnorm + mR + multDelta + mfro\n",
    "    total_divisions = dref + dgs + dnorm + dR + divDelta + divfro\n",
    "    total_sqrts = rootnorm + rootfro\n",
    "    \n",
    "    count_matrix = [(aref, mref, dref, 0), (ags, mgs, dgs, 0), (anorm, mnorm, dnorm, rootnorm), (aR, mR, dR, 0), (addDelta, multDelta, divDelta, 0), (afro, mfro, divfro, rootfro), (total_additions, total_multiplications, total_divisions, total_sqrts)]\n",
    "    \n",
    "    # Print out the operation counts\n",
    "    print(\"\\n\\nOperation Counts as follows\\n\")\n",
    "    for row, title in zip(count_matrix, [\"REF\", \"GS Algorithm\", \"Orthonormalization\", \"R = Q'A Computation\", \"(A - QR) Computation\", \"Norm(A - QR) Computation\", \"Total Count\"]):\n",
    "        print(f\"{title:<30}| A:{row[0]:<3} | M:{row[1]:<3} | D:{row[2]:<3} | Sqrt:{row[3]:<3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Analytical solution to operation counts computed above**\n",
    "\n",
    "**Row reduced Echelon form primitive operations**\n",
    "\n",
    "For this problem, we are dealing with a tall matrix A i.e. $m \\gt n$\n",
    "\n",
    "This means that our $\\text{Rank(A)} \\le n$\n",
    "\n",
    "We will therefore use elementary row operations to reduce the matrix into it's row reduced echelon form.\n",
    "\n",
    "*Consider row1*\n",
    "\n",
    "If $a_{11} = 0$, then swap $R_1$ with $R_k$ st $a_{k1} \\gt a_{i1} \\forall i \\in [2, m]$\n",
    "\n",
    "Then reduce $R_i \\forall i \\in {2,m}$ st $a_{i1} = 0$\n",
    "\n",
    "For this, we need to compute the scaling factor $\\frac{a_{i1}}{a_{11}} \\forall i \\in [2, m]$. This means we need $m - 1$ divisions in total.\n",
    "\n",
    "Next, we need to scale all but pivot elements of $R_1$ with this scaling factor. We don't have to scale the pivot because we know it will evaluate to the same number as $a_{ik}$ for the $i^{th}$ row. For this we need $n-1$ multiplications per row and we need to do this for $m-1$ rows. So in all we need $(m-1)(n-1)$ multiplications.\n",
    "\n",
    "Same case is true for additions as multiplications.\n",
    "\n",
    "\n",
    "Using the above it can be showed that for any arbitrary row $k \\lt n$, following is the count of operations required.\n",
    "\n",
    "- Additions: $(m-k)(n-k)$\n",
    "- Multiplications: $(m-k)(n-k)$\n",
    "- Divisions: $m-k$\n",
    "\n",
    "We need to sum these from $k = 1 \\text{ to }n - 1$ for obtaining the total count.\n",
    "\n",
    "$\\text{Total Additions} = \\Sigma_{1}^{n-1}(m-k)(n-k) = \\Sigma_{1}^{n-1}mn - (m+n)k +k^2$\n",
    "\n",
    "$\\text{Total Additions} = \\Sigma_{1}^{n-1}mn -  \\Sigma_{1}^{n-1} (m+n)k + \\Sigma_{1}^{n-1}k^2$\n",
    "\n",
    "$\\text{Total Additions} = mn(n-1) -\\frac{(m+n)(n)(n-1)}{2} + \\frac{n(n-1)(2n-1)}{6}$\n",
    "\n",
    "$\\therefore \\text{Total Additions} = \\frac{n(n-1)(3m-n-1)}{6}$\n",
    "\n",
    "$\\text{Simliarly, Total Multiplications} = \\frac{n(n-1)(3m-n-1)}{6}$\n",
    "\n",
    "$\\text{Total Divisions} = \\Sigma_1^{n-1}(m -k)$\n",
    "\n",
    "$\\text{Total Divisions} = \\Sigma_1^{n-1}(m) - \\Sigma_1^{n-1}k$\n",
    "\n",
    "$\\text{Total Divisions} = m(n-1) - \\frac{n(n-1)}{2}$\n",
    "\n",
    "$\\therefore \\text{Total Divisions} = \\frac{(n-1)(2m-n)}{2}$\n",
    "\n",
    "||Formula|m=7,n=5|\n",
    "|--|--|--|\n",
    "|Total Additions|$$\\frac{n(n-1)(3m-n-1)}{6}$$|50|\n",
    "|Total Multiplications|$$\\frac{n(n-1)(3m-n-1)}{6}$$|50|\n",
    "|Total Divisions|$$\\frac{(n-1)(2m-n)}{2}$$|18|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gram Schmidt Orthogonalization**\n",
    "\n",
    "Once it is established from the above REF that rank is equal to the number of columns, we are sure that the given set of columns is independent. This means we can proceed for the computation of an orthogonal set using the given linearly independent column vectors.\n",
    "\n",
    "In GS process, any $k^{th}$ orthogonal vector can be computed as \n",
    "\n",
    "$$\n",
    "v_k = x_k - \\frac{<x_k,v_1>}{<v_1,v_1>}v_1 - \\frac{<x_k,v_2>}{<v_2,v_2>}v_2 - ... -  \\frac{<x_k,v_{k-1}>}{<v_{k-1},v_{k-1}>}v_{k-1} \\forall k \\in [2, n]\n",
    "$$\n",
    "\n",
    "where $<>$ denotes inner product of the two column vectors.\n",
    "\n",
    "So, let's try to compute the operation counts here.\n",
    "\n",
    "Before taking any specific row, the inner product of two column vectors each of size $m \\times 1$ can be computed as\n",
    "\n",
    "$$\n",
    "<x,y> = x_1y_1 + x_2y_2 + ... + x_{m-1}y_{m-1} + x_my_m\n",
    "$$\n",
    "\n",
    "This means there are as many multiplications as the number of elements in each vector and one less addition. So, we have for every dot product, multiplications = $m$; additions = $m-1$.\n",
    "\n",
    "Similarly scaling a vector or adding two vectors are operations wherein each element of the vector is involved. So, in both these cases, multiplications = $m$ and additions = $m$ respectively.\n",
    "\n",
    "Now let's get to the computation of elements for the $k^{th}$ column.\n",
    "\n",
    "Since we have to **subtract** some multiple of previously obtained $v_i$ columns, we need to compute $k-1$ vector additions.\n",
    "\n",
    "Since we have to subtract **some multiple** of previously obtained $v_i$ columns, we need to compute $k-1$ scalar multiplications of these $v_i$ column vectors.\n",
    "\n",
    "If we closely observe the scaling factors, we will notice there are two terms\n",
    "\n",
    "- $<x_i,v_i>$ terms. These will have to be calculated at any cost. So we have those $k-1$ dot product computations.\n",
    "- $<v_i,v_i>$ terms. These are interesting ones. We only need to compute the result for $<v_i,v_i>$ once and we can keep reusing it. So, for $k^{th}$ row, we already have $v_i$ values for all $i \\le k-2$. We only have to compute one more dot product of $<v_{k-1},v_{k-1}>$.\n",
    "- Since there are $k-1$ fractions, we need those many divisions.\n",
    "\n",
    "So, we need to compute $k$ dot products and $k-1$ divisions for $k^{th}$ row.\n",
    "\n",
    "This means in all we have\n",
    "\n",
    "- $k$ dot products meaning $k(m-1)$ additions and $km$ multiplications\n",
    "- $k - 1$ divisions\n",
    "- $k - 1$ vector additions meaning $(k-1)m$ additions\n",
    "- $k - 1$ vector scalings meaning $(k-1)m$ multiplications\n",
    "\n",
    "When expressed in terms of counts, we get,\n",
    "\n",
    "$\\text{Total Additions} = \\Sigma_{2}^{n}k(m-1) + (k-1)m$\n",
    "\n",
    "$\\text{Total Additions} = \\Sigma_{2}^{n}km + (k-1)m$\n",
    "\n",
    "$\\text{Total Divisions} = \\Sigma_{2}^{n}(k-1)m$\n",
    "\n",
    "Solving these, we finally arrive at the total counts as follows\n",
    "\n",
    "||Formula|m=7,n=5|\n",
    "|--|--|--|\n",
    "|Total Additions|$$m(n^2-1)-\\frac{n(n+1)}{2} +1$$|154|\n",
    "|Total Multiplications|$$m(n^2-1)$$|168|\n",
    "|Total Divisions|$$\\frac{n(n-1)}{2}$$|10|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalization**\n",
    "\n",
    "In normalization, we want to do a columnwise normalization for each column of the given matrix. Each column is a $m \\times 1$ vector.\n",
    "\n",
    "We first need to compute the elementwise product of each element in column. If m-dimensional, we have $m$ multiplications.\n",
    "\n",
    "Then we need to sum them all together, summing m elements will take $m-1$ additions.\n",
    "\n",
    "Then we need to compute the square root of that element, which will take $1$ sqrt operation.\n",
    "\n",
    "Next we need to divide each element of the column vector by the above computed norm which will take $m$ divisions.\n",
    "\n",
    "This process needs to happen for each of the $n$ columns in the given matrix.\n",
    "\n",
    "So we can tabulate the total operation counts as follows\n",
    "\n",
    "||Formula|m=7,n=5|\n",
    "|--|--|--|\n",
    "|Total Additions|$$(m-1)n$$|30|\n",
    "|Total Multiplications|$$mn$$|35|\n",
    "|Total Divisions|$$mn$$|35|\n",
    "|Total Sqrts|$$n$$|5|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix Multiplication**\n",
    "\n",
    "Consider a matrix $A_{m \\times n}$ and another matrix $Q^T_{n \\times m}$\n",
    "\n",
    "Matrix multiplication involves computation of inner products. \n",
    "\n",
    "In the product $C = Q^TA$ there will be $n$ rows and $n$ columns and each of them will be the inner product of 2 $m$ dimensional vectors.\n",
    "\n",
    "So we are effectively performing $n^2$ inner products of two $m$ dimensional vectors.\n",
    "\n",
    "We saw above that we only need additions and multiplications to perform this task and that for each product, we need $m$ multiplications and $m-1$ divisions.\n",
    "\n",
    "So we can tabulate the total operation counts as follows\n",
    "\n",
    "||Formula|m=7,n=5|\n",
    "|--|--|--|\n",
    "|Total Additions|$$n^2(m-1)$$|150|\n",
    "|Total Multiplications|$$n^2m$$|175|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frobenius Norm Calculation**\n",
    "\n",
    "Consider a matrix $A_{m \\times n}$\n",
    "\n",
    "For computation of frobenius norm,\n",
    "\n",
    "- We should multiply ever element with itself which means we will end up with $mn$ multiplications\n",
    "- We need to compute the sum of the elements obtained above which will take us $mn-1$ additions\n",
    "- We finally need to take the square root of the sum obtained above\n",
    "\n",
    "So we can tabulate the total operation counts as follows\n",
    "\n",
    "||Formula|m=7,n=5|\n",
    "|--|--|--|\n",
    "|Total Additions|$$mn-1$$|34|\n",
    "|Total Multiplications|$$mn$$|35|\n",
    "|Total Sqrts|$$1$$|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: Gradient Descent Algorithm\n",
    "\n",
    "**i**: Consider the last 4 digits of your mobile number (Note : In case there is a 0 in one of the digits replace it by 3). Let it be $n_1n_2n_3n_4$. Generate a random matrix A of size $n_1n_2 \\times n_3n_4$. For example, if the last four digits are 2311, generate a random matrix of size 23 × 11. Write a code to calculate the $l_{\\infty}$ norm of this matrix.\n",
    "\n",
    "> **Deliverable(s) : The code that generates the results. (0.5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gradient_descent_matrix() -> Tuple:\n",
    "    \"\"\"[Creates a matrix of the size n1n2 * n3n4 and a matrix b of size n1n2 * 1]\n",
    "\n",
    "    Returns:\n",
    "        List: A matrix in the form of a list\n",
    "    \"\"\"\n",
    "\n",
    "    # Prompt the user for his mobile number\n",
    "    \n",
    "    # Ascertain the mobile number is valid\n",
    "    number = input(\"Enter your phone number:\\n\")\n",
    "    try:\n",
    "        n = int(number)\n",
    "        if len(number.strip()) != 10:\n",
    "            print(\"Mobile number must have exactly 10 digits. Please enter a valid number\")\n",
    "            return ([], [])\n",
    "    except Exception as e:\n",
    "        print(f\"{str(e)}\\nEntered number invalid. Please enter a valid number\")\n",
    "        return ([], [])\n",
    "    \n",
    "    # Get the last 4 digits of the number and replace\n",
    "    # 0s in the number with 3s\n",
    "    rc = number.strip()[-4:]\n",
    "    rc = rc.replace(\"0\", \"3\")\n",
    "\n",
    "    nr, nc = int(rc[:2]), int(rc[2:])\n",
    "    matrix = create_random_matrix(nr, nc, wide = True)\n",
    "    b = create_random_matrix(nr, 1, wide = True)\n",
    "    \n",
    "    return (matrix, b)\n",
    "\n",
    "def linf_norm(matrix: List) -> float:\n",
    "    \"\"\"[Given a matrix computes it's linfinity norm]\n",
    "\n",
    "    Args:\n",
    "        matrix (List): [Matrix represented as a list of numbers]\n",
    "\n",
    "    Returns:\n",
    "        float: The infinity norm of the said matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    inf_norm = 0\n",
    "\n",
    "    # For each row in the matrix\n",
    "    for row in matrix:\n",
    "        rsum = 0\n",
    "\n",
    "        # Compute the row sum of absolute vals of elements in that row\n",
    "        for element in row:\n",
    "            rsum += abs(element)\n",
    "\n",
    "        # Store the largest row sum\n",
    "        if rsum > inf_norm:\n",
    "            inf_norm = rsum\n",
    "    return inf_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your phone number:\n",
      " sdcadf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid literal for int() with base 10: 'sdcadf'\n",
      "Entered number invalid. Please enter a valid number\n"
     ]
    }
   ],
   "source": [
    "# Create the gradient descent matrices A & b. \n",
    "# Validate the input to have a proper mobile number\n",
    "A, b = generate_gradient_descent_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your phone number:\n",
      " 6584684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile number must have exactly 10 digits. Please enter a valid number\n"
     ]
    }
   ],
   "source": [
    "# Create the gradient descent matrices A & b. \n",
    "# Validate the input to have a proper mobile number\n",
    "A, b = generate_gradient_descent_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your phone number:\n",
      " 6464684684646464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile number must have exactly 10 digits. Please enter a valid number\n"
     ]
    }
   ],
   "source": [
    "# Create the gradient descent matrices A & b. \n",
    "# Validate the input to have a proper mobile number\n",
    "A, b = generate_gradient_descent_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your phone number:\n",
      " 7738368566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L-inf norm of the generated matrix A is 376.30050\n"
     ]
    }
   ],
   "source": [
    "# Create the gradient descent matrices A & b. \n",
    "# Validate the input to have a proper mobile number\n",
    "A, b = generate_gradient_descent_matrix()\n",
    "print(f\"L-inf norm of the generated matrix A is {linf_norm(A):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii** Generate a random vector b of size $n_1n_2 \\times 1$ and consider the function $f(x) = \\frac{1}{2}||Ax - b||_2^2$ where $|| \\cdot ||_2$ is the vector $l_2$ norm. Its gradient is given to be $\\nabla f(x) = A^TAx - A^Tb$. Write a code to find the local minima of this function by using the gradient descent algorithm (by using the gradient expression given to you). The step size $\\tau$ in the iteration $x_k + 1 = x_k − \\tau \\nabla f(x_k)$ should be chosen by the formula \n",
    "\n",
    "$$\n",
    "\\tau = \\frac{g_k^Tg_k}{g_k^TA^TAg_k}\n",
    "$$\n",
    "\n",
    "where $g_k = \\nabla f(x_k) = A^TAx_k - A^Tb$ The algorithm should execute\n",
    "until $||x_k - x_{k - 1}||_2 < 10^{-4}$.\n",
    "\n",
    "> **Deliverable(s) : The code that finds the minimum of the given function and the expression for $\\tau$. The values of $x_k$ and $f(x_k)$ should be stored in a file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(stopping_threshold:float = 1e-4) -> List:\n",
    "    \"\"\"[Generates a random matrix based on user's mobile number, performs gradient descent and returns the solutions of the system of equation and intermediate steps taken]\n",
    "    \n",
    "    Args:\n",
    "        stopping_threshold (float): [When to stop iterating, i.e. convergence criterion]\n",
    "        \n",
    "    Returns:\n",
    "        List: [A list of solutions, intermediate values and function values at each step]\n",
    "    \"\"\"\n",
    "    \n",
    "    A, b = generate_gradient_descent_matrix()\n",
    "    n_equations, n_features = len(A), len(A[0])\n",
    "    \n",
    "    # Start with an initial guess of all zeros\n",
    "    current_solution = [[0.0] for r in range(n_features)]\n",
    "    optimization_steps = []\n",
    "\n",
    "    # Begin optimization here\n",
    "    while True:\n",
    "        \n",
    "        # Find out the function value\n",
    "        result = matrix_multiplication(A, current_solution)[0]\n",
    "        scaled_b = scalar_multiplication(flatten_column_matrix(b), -1)[0]\n",
    "        f = vector_addition(flatten_column_matrix(result), scaled_b)[0]\n",
    "        fn = frob_norm(expand_column_vector(f))[0]\n",
    "        func_val = 0.5 * (fn ** 2)\n",
    "        \n",
    "\n",
    "        # Find the gradient of the function at the current step \n",
    "        # i. Find AtAx\n",
    "        A_transpose = matrix_transpose(A)\n",
    "        AtA = matrix_multiplication(A_transpose, A)[0]\n",
    "        AtAx = matrix_multiplication(AtA, current_solution)[0]\n",
    "        \n",
    "        # ii. Find Atb\n",
    "        Atb = matrix_multiplication(A_transpose, b)[0]\n",
    "        \n",
    "        # iii. Find AtAx - Atb\n",
    "        scaled_Atb = scalar_multiplication(flatten_column_matrix(Atb), -1)[0]\n",
    "        gradf = vector_addition(flatten_column_matrix(AtAx), scaled_Atb)[0]\n",
    "        gradf = expand_column_vector(gradf)\n",
    "        \n",
    "        # Compute the learning rate\n",
    "        gradf_transpose = matrix_transpose(gradf)\n",
    "        tau_nr = matrix_multiplication(gradf_transpose, gradf)[0][0][0]\n",
    "        tau_dr = matrix_multiplication(gradf_transpose, matrix_multiplication(AtA, gradf)[0])[0][0][0]\n",
    "        # To avoid numerical instability, add a very tiny epsilon to the denominator\n",
    "        learning_rate = tau_nr / (tau_dr + 1e-16)\n",
    "        \n",
    "        # Take a step in the opposite direction of the gradient\n",
    "        previous_solution = current_solution\n",
    "        scaled_gradf = scalar_multiplication(flatten_column_matrix(gradf), -1 * learning_rate)[0]\n",
    "        current_solution = vector_addition(flatten_column_matrix(previous_solution), scaled_gradf)[0]\n",
    "        current_solution = expand_column_vector(current_solution)\n",
    "        \n",
    "        # Define the stopping criterion\n",
    "        scaled_prev_sol = scalar_multiplication(flatten_column_matrix(previous_solution), -1)[0]\n",
    "        step_delta = vector_addition(flatten_column_matrix(current_solution), scaled_prev_sol)[0]\n",
    "        \n",
    "        stopping_threshold = frob_norm(expand_column_vector(step_delta))[0]\n",
    "        if abs(stopping_threshold) <= 1e-4:\n",
    "            break\n",
    "\n",
    "        optimization_steps.append([previous_solution, gradf, func_val])\n",
    "    \n",
    "    return optimization_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your phone number:\n",
      " 7738368566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the history of xk, gradient of f at xk and f(xk) to solutions.txt file\n"
     ]
    }
   ],
   "source": [
    "# Perform gradient descent by prompting the user for phone number and store the result obtained in a \n",
    "# CSV file with the points, gradients and the function value at that point \n",
    "solutions = gradient_descent()\n",
    "\n",
    "with open(\"solutions.txt\", \"w\") as f:\n",
    "    for sol in solutions:\n",
    "        f.writelines(f\"{sol[0]},{sol[1]},{sol[2]}\\n\")\n",
    "\n",
    "print(\"Saved the history of xk, gradient of f at xk and f(xk) to solutions.txt file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii** Generate the graph of $f(x_k)$ vs $k$ where $k$ is the iteration number and $x_k$ is the current estimate of $x$ at iteration $k$. This graph should convey the decreasing nature of function values.\n",
    "\n",
    "> **Deliverable(s) : The graph that is generated.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "fig, ax = plt.subplots(1, 1, figsize = (15,4))\n",
    "\n",
    "function_values = [x[2] for x in solutions]\n",
    "plt.plot(range(len(solutions)), function_values, )\n",
    "plt.xlabel(\"Iteration Number\", fontsize = 20)\n",
    "plt.ylabel(\"Function Value\", fontsize = 20)\n",
    "plt.title(\"Gradient Descent Optimization Plot\", fontsize = 20);\n",
    "plt.xlim([-10,10 + len(solutions)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$\n",
    "\n",
    "# Critical points of polynomial function\n",
    "\n",
    "**i** Generate a third degree polynomial in $x$ and $y$ named $g(x,y)$ that is based on your mobile number (Note : In case there is a 0 in one of the\n",
    "digits replace it by 3). Suppose your mobile number is $9412821233$, then the polynomial would be \n",
    "\n",
    "$$ \n",
    "g(x,y) = 9x^3 - 4x^2y + 1xy^2 -2y^3 +8x^2 -2xy + 1y^2 -2x + 3y -3\n",
    "$$\n",
    "\n",
    "where alternate positive and negative sign are used. \n",
    "\n",
    "> **Deliverable(s) : The polynomial constructed should be reported. (0.5)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```octave\n",
    "## Author: vinayak <vinayak@vinayak-EXIGO-V2>\n",
    "## Created: 2022-02-21\n",
    "% Script to read a phone number and create a polynomial \n",
    "\n",
    "function [pol] = qn31()\n",
    "  a = input(\"Enter your mobile number\\n\");\n",
    "  % Allocate memory for the polynomial to be created\n",
    "  pol = []; \n",
    "  num = a;\n",
    "  counter = 1;\n",
    "  \n",
    "  % Parse through the input number and then convert them \n",
    "  % into a vector of values in sequential manner\n",
    "  % Alternate +ve and -ve signs for co-efficients\n",
    "  % If a zero is present in the number, substitute it with +-3\n",
    "  while num > 1,\n",
    "    \n",
    "    x = mod(num, 10);\n",
    "    if x == 0,\n",
    "      x = 3;\n",
    "    endif;  \n",
    "    \n",
    "    if mod(counter, 2) == 1,\n",
    "      x = -x;\n",
    "    endif;  \n",
    "    \n",
    "    pol = [pol; x];\n",
    "    num = idivide(num, 10);\n",
    "    counter = counter + 1;\n",
    "  endwhile\n",
    "  \n",
    "  % Flip around the polynomial co-efficients\n",
    "  pol = transpose(flip(pol));\n",
    "  displayPolynomial(pol);\n",
    "end\n",
    "\n",
    "function [] = displayPolynomial(pol)\n",
    "    % Function to display the formed polynomial\n",
    "    polynomial_terms = [\"x^3\"; \"x^2y\"; \"xy^2 \"; \"y^3\"; \"x^2\"; \"xy\"; \"y^2\"; \"x\"; \"y\"; \" \"];\n",
    "    poly_str = [\"\"];\n",
    "    \n",
    "    for i=1:length(pol),\n",
    "      if mod(i,2) == 0,\n",
    "        poly_str = [poly_str num2str(pol(i)) polynomial_terms(i, :)];\n",
    "      else\n",
    "        poly_str = [poly_str \" +\" num2str(pol(i)) polynomial_terms(i, :)];\n",
    "      endif\n",
    "    endfor\n",
    "    \n",
    "    printf(\"Polynomial generated from the entered mobile number\\n\");\n",
    "    disp(poly_str);\n",
    "    \n",
    "endfunction\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](qn31.png)\n",
    "\n",
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii** Write a code to find all critical points of $g(x, y)$. You may use built in functions like `solve` (or other similar functions) in Octave/Matlab to find the critical points. \n",
    "\n",
    "> **Deliverable(s) : The code that finds the critical points along with the display of all the calculated critical points. (1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](32_critical_points.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```octave\n",
    "## Author: vinayak <vinayak@vinayak-EXIGO-V2>\n",
    "## Created: 2022-02-23\n",
    "% Script to find out the critical points of a polynomial\n",
    "\n",
    "function [critical_points] = qn32(pol)\n",
    "  \n",
    "  % Display the polynomial created from the given cell number\n",
    "  disp(\"Polynomial co-efficients entered is as follows\");\n",
    "  disp(pol);\n",
    "  \n",
    "  % Create a container to hold the solution values\n",
    "  critical_points = [];\n",
    "  \n",
    "  % Find out the critical points using fsolve\n",
    "  % Start at different points in the function domain using random\n",
    "  % Variables and then find the roots of grad(pol) = 0\n",
    " \n",
    "  for i = 1:1000,\n",
    "    % Define the start point\n",
    "    startPoint = 1000 * randn(2, 1);\n",
    "    % Create a wrapper function for the objective/optimization function\n",
    "    optimFunc = @(pol) @(startPoint) optimizationFunction(startPoint, pol);\n",
    "    % Define the solver options\n",
    "    options = optimset (\"TolFun\", 1e-6, \"MaxIter\", 5000);\n",
    "    % Find solutions to the above objective function\n",
    "    [sol, fval, info] = fsolve(optimFunc(pol), startPoint, options);\n",
    "    % If the solution converged in this iteration, save the \n",
    "    % Point as a critical point in the matrix\n",
    "    if info == 1,\n",
    "      critical_points = addToSolution(critical_points, sol);\n",
    "    endif;\n",
    "  endfor\n",
    "  \n",
    "endfunction\n",
    "\n",
    "function [distance] = euclideanDistance(v1, v2)\n",
    "  % Given two vectors v1 and v2, compute the Euclidean distance between them\n",
    "  distance = sqrt(sum((v1 - v2).^2));\n",
    "endfunction\n",
    "\n",
    "function [sol] = addToSolution(solutionSet, newSolution)\n",
    "  % Given a set of critical points and a new critical point\n",
    "  % Check if the new point is already present in the given set\n",
    "  % If no, add it to the solution set, else return the set as is\n",
    "  n = size(solutionSet)(2);\n",
    "  present = 0;\n",
    "  for i = 1:n,\n",
    "    r = euclideanDistance(solutionSet(:, i), newSolution);\n",
    "    if r < 1e-6,\n",
    "      present = 1;\n",
    "      break;\n",
    "    endif  \n",
    "  endfor  \n",
    "  \n",
    "  % If the solution doesn't exist in the current set, add it to\n",
    "  % The current set, otherwise, just return old solution set as is\n",
    "  if present == 0,\n",
    "    sol = [solutionSet, newSolution];\n",
    "  else\n",
    "    sol = solutionSet;\n",
    "  endif;  \n",
    "  \n",
    "endfunction  \n",
    "\n",
    "function [out] = optimizationFunction(startPoint, g)\n",
    "  % Start with the x and y values at this given step\n",
    "  x = startPoint(1);\n",
    "  y = startPoint(2);\n",
    "  \n",
    "  % Solve for delg/delx = 0; delg/dely = 0 simultaneously\n",
    "  gx = 3*g(1)*x^2 + 2*g(2)*x*y + g(3)*y^2 + 2*g(5)*x + g(6)*y + g(8);  \n",
    "  gy = g(2)*x^2 + 2*g(3)*x*y + 3*g(4)*y^2 + g(6)*x + 2*g(7)*y + g(9);\n",
    "  out = [gx gy];\n",
    "endfunction\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](qn32.png)\n",
    "\n",
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**iii** Write a code to determine whether they correspond to a maximum, minimum or a saddle point.\n",
    "\n",
    "\n",
    "> **Deliverable(s) : The code that identifies the type of critical points. The critical points and their type must be presented in the form of the table\n",
    "generated by code for the above polynomial.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](33_hessian.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```octave\n",
    "## Author: vinayak <vinayak@vinayak-EXIGO-V2>\n",
    "## Created: 2022-02-23\n",
    "% Script to find out the nature of critical points of a polynomial function in 2 variables\n",
    "\n",
    "function [] = qn33 (pol)\n",
    "  \n",
    "  % Call the routine to take input and find the critical points of a function\n",
    "  [cp] = qn32(pol);\n",
    "  \n",
    "  % Iterate over the individual points, find out their nature and tabulate them\n",
    "  % Find out the number of critical points obtained\n",
    "  n = size(cp)(2);\n",
    "  \n",
    "  for i = 1:n,\n",
    "    [evals, nature] = hessian(pol, cp(:, i));\n",
    "    printf(\"\\nCritical Point\\n\");%, num2str(i));\n",
    "    disp(transpose(cp(:, i)));\n",
    "    printf(\"\\nEigen Values of Hessian for this critical point as follows\\n\");\n",
    "    disp(evals);\n",
    "    printf(\"\\nNature of the critical point: \");\n",
    "    disp(nature);\n",
    "  endfor\n",
    "  \n",
    "endfunction\n",
    "\n",
    "function [evals, nature] = hessian(g, cp)\n",
    "  % Given a polynomial and it's critical point, computes the\n",
    "  % hessian matrix and it's eigen values at this point\n",
    "  x = cp(1, 1); y = cp(2, 1);\n",
    "  \n",
    "  % Define the second order partial derivative hessian matrix\n",
    "  h11 = 6*g(1)*x + 2*g(2)*y + 2*g(5);\n",
    "  h12 = 2*g(2)*x + 2*g(3)*y + g(6);\n",
    "  h21 = h12;\n",
    "  h22 = 2*g(3)*x + 6*g(4)*y + 2*g(7);  \n",
    "  hessian = [h11 h12; h21 h22];\n",
    "  \n",
    "  % Find the eigen vector/eigen value pairs for the hessian matrix\n",
    "  [_, evs] = eigs(hessian);\n",
    "  \n",
    "  % Find out the nature of evs\n",
    "  sgn = 1;\n",
    "  evals = [];\n",
    "  for i = 1:length(evs),\n",
    "    sgn = sign(evs(i,i)) * sgn;\n",
    "    evals = [evals evs(i, i)];\n",
    "  endfor  \n",
    "  \n",
    "  % If all eigen values of hessian > 0 ===> Minima\n",
    "  % If all eigen values of hessian < 0 ===> Maxima\n",
    "  % If both +ve & -ve eigen values     ===> Saddle\n",
    "  if sgn == -1,\n",
    "    nature = \"saddle\";\n",
    "  elseif (sgn == 1) && (evs(1,1) > 0),\n",
    "    nature = \"minima\";\n",
    "  elseif (sgn == 1) && (evs(1,1) < 0),\n",
    "    nature = \"maxima\";\n",
    "  endif  \n",
    "endfunction\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](qn33.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
